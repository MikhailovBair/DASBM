{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9007660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the NVIDIA Source Code License\n",
    "# for Denoising Diffusion GAN. To view a copy of this license, see the LICENSE file.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset\n",
    "from discrete_ot import OTPlanSampler\n",
    "\n",
    "\n",
    "from torch.multiprocessing import Process\n",
    "import torch.distributed as dist\n",
    "import shutil\n",
    "import pdb\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datetime import datetime\n",
    "datetime_marker_str = datetime.now().strftime(\"%d:%m:%y_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d0314",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329b4c7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "fid_n_samples = 100\n",
    "eps = 1\n",
    "\n",
    "T = 4\n",
    "exp_name = 'BMGAN_Cifar_downsample'\n",
    "mini_batch_OT = False\n",
    "plan = 'ind'\n",
    "\n",
    "D_opt_steps = 2\n",
    "ema_decay = 0.99\n",
    "\n",
    "ipmf_iters = 20\n",
    "markovian_proj_iters = 10000 #30000\n",
    "\n",
    "inner_ipmf_mark_proj_iters = 2000 #10000\n",
    "\n",
    "mini_batch_OT = 0\n",
    "\n",
    "ema_start_ipmf = 0\n",
    "\n",
    "device = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd87e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mini_batch_OT > 0:\n",
    "    mini_batch_OT = True\n",
    "else:\n",
    "    mini_batch_OT = False\n",
    "\n",
    "if ema_start_ipmf > 0:\n",
    "    ema_start_ipmf = True\n",
    "else:\n",
    "    ema_start_ipmf = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac428edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {'eps': eps, 'T': T, 'mini_batch_OT': mini_batch_OT, 'D_opt_steps': D_opt_steps, 'ema_decay': ema_decay,\n",
    "'ipmf_iters': ipmf_iters, 'markovian_proj_iters': markovian_proj_iters, \n",
    "'inner_ipmf_mark_proj_iters': inner_ipmf_mark_proj_iters, 'ema_start_ipmf': ema_start_ipmf, 'plan': plan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04232f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def config_to_expdir(config):\n",
    "    exp_dir = datetime_marker_str\n",
    "    \n",
    "    for key, value in config.items():\n",
    "        exp_dir += str(key) + '=' + str(value) + '\\\\'\n",
    "        \n",
    "    return exp_dir\n",
    "\n",
    "save_dir = config_to_expdir(config)\n",
    "\n",
    "os.makedirs(os.path.join(exp_name, save_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3617af0",
   "metadata": {},
   "source": [
    "## Helper functions and posterior sampling\n",
    "\n",
    "including p(x_t | x_0, x_1) from Brownian Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f6fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FID calculation\n",
    "def normalize_tensor(tensor):\n",
    "    normalized = tensor / 2 + 0.5\n",
    "    return normalized.clamp_(0, 1)\n",
    "\n",
    "\n",
    "def to_uint8_tensor(tensor):\n",
    "    tensor = normalize_tensor(tensor)\n",
    "    return tensor.mul(255).add_(0.5).clamp_(0, 255).to(torch.uint8)\n",
    "\n",
    "\n",
    "def compute_fid_and_ot_cost(true_dataloader, model_input_dataloader, sample_fn):\n",
    "    # backward loader y -> x\n",
    "    ot_cost = 0\n",
    "    fid = FrechetInceptionDistance().to(device)\n",
    "    \n",
    "    for item in iter(true_dataloader):\n",
    "        x = item[0]\n",
    "        fid.update(to_uint8_tensor(x.expand(-1, 3, -1, -1)).to(device), real=True)\n",
    "\n",
    "    for item in iter(model_input_dataloader):\n",
    "        y = item[0]\n",
    "        fake_sample = sample_fn(y.to(device))\n",
    "        fid.update(to_uint8_tensor(fake_sample.expand(-1, 3, -1, -1)), real=False)\n",
    "\n",
    "        ot_cost += F.mse_loss(fake_sample.to(device), y.to(device)) * y.shape[0]\n",
    "\n",
    "    ot_cost = ot_cost / 10000\n",
    "        \n",
    "    return fid.compute(), ot_cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3baed17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_source(file, output_dir):\n",
    "    shutil.copyfile(file, os.path.join(output_dir, os.path.basename(file)))\n",
    "            \n",
    "def broadcast_params(params):\n",
    "    for param in params:\n",
    "        dist.broadcast(param.data, src=0)\n",
    "\n",
    "\n",
    "#%% Diffusion coefficients \n",
    "def var_func_vp(t, beta_min, beta_max):\n",
    "    log_mean_coeff = -0.25 * t ** 2 * (beta_max - beta_min) - 0.5 * t * beta_min\n",
    "    var = 1. - torch.exp(2. * log_mean_coeff)\n",
    "    return var\n",
    "\n",
    "def var_func_geometric(t, beta_min, beta_max):\n",
    "    return beta_min * ((beta_max / beta_min) ** t)\n",
    "\n",
    "def extract(input, t, shape):\n",
    "    out = torch.gather(input, 0, t)\n",
    "    reshape = [shape[0]] + [1] * (len(shape) - 1)\n",
    "    out = out.reshape(*reshape)\n",
    "\n",
    "    return out\n",
    "\n",
    "def get_time_schedule(args, device):\n",
    "    n_timestep = args.num_timesteps\n",
    "    eps_small = 1e-3\n",
    "    t = np.arange(0, n_timestep + 1, dtype=np.float64)\n",
    "    t = t / n_timestep\n",
    "    t = torch.from_numpy(t) * (1. - eps_small)  + eps_small\n",
    "    return t.to(device)\n",
    "\n",
    "def get_sigma_schedule(args, device):\n",
    "    n_timestep = args.num_timesteps\n",
    "    beta_min = args.beta_min\n",
    "    beta_max = args.beta_max\n",
    "    eps_small = 1e-3\n",
    "   \n",
    "    t = np.arange(0, n_timestep + 1, dtype=np.float64)\n",
    "    t = t / n_timestep\n",
    "    t = torch.from_numpy(t) * (1. - eps_small) + eps_small\n",
    "    \n",
    "    if args.use_geometric:\n",
    "        var = var_func_geometric(t, beta_min, beta_max)\n",
    "    else:\n",
    "        var = var_func_vp(t, beta_min, beta_max)\n",
    "    alpha_bars = 1.0 - var\n",
    "    betas = 1 - alpha_bars[1:] / alpha_bars[:-1]\n",
    "    \n",
    "    first = torch.tensor(1e-8)\n",
    "    betas = torch.cat((first[None], betas)).to(device)\n",
    "    betas = betas.type(torch.float32)\n",
    "    sigmas = betas**0.5\n",
    "    a_s = torch.sqrt(1-betas)\n",
    "    return sigmas, a_s, betas\n",
    "\n",
    "class Diffusion_Coefficients():\n",
    "    def __init__(self, args, device):\n",
    "                \n",
    "        self.sigmas, self.a_s, _ = get_sigma_schedule(args, device=device)\n",
    "        self.a_s_cum = np.cumprod(self.a_s.cpu())\n",
    "        self.sigmas_cum = np.sqrt(1 - self.a_s_cum ** 2)\n",
    "        self.a_s_prev = self.a_s.clone()\n",
    "        self.a_s_prev[-1] = 1\n",
    "        \n",
    "        self.a_s_cum = self.a_s_cum.to(device)\n",
    "        self.sigmas_cum = self.sigmas_cum.to(device)\n",
    "        self.a_s_prev = self.a_s_prev.to(device)\n",
    "    \n",
    "def q_sample(coeff, x_start, t, *, noise=None):\n",
    "    \"\"\"\n",
    "    Diffuse the data (t == 0 means diffused for t step)\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "      noise = torch.randn_like(x_start)\n",
    "      \n",
    "    x_t = extract(coeff.a_s_cum, t, x_start.shape) * x_start + \\\n",
    "          extract(coeff.sigmas_cum, t, x_start.shape) * noise\n",
    "    \n",
    "    return x_t\n",
    "\n",
    "def q_sample_supervised(pos_coeff, x_start, t, x_end, *, noise=None):\n",
    "    \"\"\"\n",
    "    Diffuse the data (t == 0 means diffused for t step)\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "      noise = torch.randn_like(x_start)\n",
    "\n",
    "    T = len(coeff.a_s_cum)\n",
    "\n",
    "    x_t = x_end\n",
    "    for t_current in reversed(list(range(t[0], T))):\n",
    "        t_tensor = torch.full((x_t.size(0),), t_current, dtype=torch.int64).to(x_t.device)\n",
    "        x_t = sample_posterior(pos_coeff, x_start, x_t, t_tensor)\n",
    "    \n",
    "    return x_t\n",
    "\n",
    "def q_sample_pairs(coeff, x_start, t):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_start)\n",
    "    x_t = q_sample(coeff, x_start, t)\n",
    "    x_t_plus_one = extract(coeff.a_s, t+1, x_start.shape) * x_t + \\\n",
    "                   extract(coeff.sigmas, t+1, x_start.shape) * noise\n",
    "    \n",
    "    return x_t, x_t_plus_one\n",
    "\n",
    "def q_sample_supervised_pairs(pos_coeff, x_start, t, x_end):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "#     noise = torch.randn_like(x_start)\n",
    "    T = pos_coeff.posterior_mean_coef1.shape[0]\n",
    "\n",
    "    x_t_plus_one = x_end\n",
    "    t_current = T\n",
    "\n",
    "    while t_current != t[0]:\n",
    "        t_tensor = torch.full((x_end.size(0),), t_current-1, dtype=torch.int64).to(x_end.device)\n",
    "        x_t_plus_one = sample_posterior(pos_coeff, x_start, x_t_plus_one, t_tensor)\n",
    "        t_current -= 1\n",
    "\n",
    "    t_tensor = torch.full((x_end.size(0),), t_current, dtype=torch.int64).to(x_end.device)\n",
    "    x_t = sample_posterior(pos_coeff, x_start, x_t_plus_one, t_tensor)\n",
    "    \n",
    "    return x_t, x_t_plus_one\n",
    "\n",
    "\n",
    "def q_sample_supervised_pairs_brownian(pos_coeff, x_start, t, x_end):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_start)\n",
    "    num_steps = pos_coeff.posterior_mean_coef1.shape[0]\n",
    "    t_plus_one_tensor = ((t+1)/num_steps)[:, None, None, None]\n",
    "\n",
    "    x_t_plus_one = t_plus_one_tensor*x_end + (1.0 - t_plus_one_tensor)*x_start + torch.sqrt(pos_coeff.epsilon*t_plus_one_tensor*(1-t_plus_one_tensor))*noise\n",
    "    \n",
    "    x_t = sample_posterior(pos_coeff, x_start, x_t_plus_one, t)\n",
    "    \n",
    "    return x_t, x_t_plus_one\n",
    "\n",
    "\n",
    "def q_sample_supervised_trajectory(pos_coeff, x_start, x_end):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "#     noise = torch.randn_like(x_start)\n",
    "    trajectory = [x_end]\n",
    "    T = pos_coeff.posterior_mean_coef1.shape[0]\n",
    "\n",
    "    x_t_plus_one = x_end\n",
    "    t_current = T\n",
    "\n",
    "    while t_current != 0:\n",
    "        t_tensor = torch.full((x_end.size(0),), t_current-1, dtype=torch.int64).to(x_end.device)\n",
    "        x_t_plus_one = sample_posterior(pos_coeff, x_start, x_t_plus_one, t_tensor)\n",
    "        t_current -= 1\n",
    "        trajectory.append(x_t_plus_one)\n",
    "\n",
    "    t_tensor = torch.full((x_end.size(0),), t_current, dtype=torch.int64).to(x_end.device)\n",
    "    x_t = sample_posterior(pos_coeff, x_start, x_t_plus_one, t_tensor)\n",
    "    trajectory.append(x_t)\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "#%% posterior sampling\n",
    "class Posterior_Coefficients():\n",
    "    def __init__(self, args, device):\n",
    "        \n",
    "        _, _, self.betas = get_sigma_schedule(args, device=device)\n",
    "        \n",
    "        #we don't need the zeros\n",
    "        self.betas = self.betas.type(torch.float32)[1:]\n",
    "        \n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, 0)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "                                    (torch.tensor([1.], dtype=torch.float32,device=device), self.alphas_cumprod[:-1]), 0\n",
    "                                        )               \n",
    "        self.posterior_variance = self.betas * (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod)\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.rsqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1 / self.alphas_cumprod - 1)\n",
    "        \n",
    "        self.posterior_mean_coef1 = (self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1 - self.alphas_cumprod))\n",
    "        self.posterior_mean_coef2 = ((1 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1 - self.alphas_cumprod))\n",
    "        \n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min=1e-20))\n",
    "\n",
    "\n",
    "class BrownianPosterior_Coefficients():\n",
    "    def __init__(self, args, device):\n",
    "        epsilon = args.epsilon\n",
    "        self.epsilon = epsilon\n",
    "        num_timesteps = args.num_timesteps\n",
    "\n",
    "        t = torch.linspace(0, 1, num_timesteps+1, device=device)\n",
    "        self.posterior_mean_coef1 = 1 - t[:-1]/t[1:]\n",
    "        self.posterior_mean_coef2 = t[:-1]/t[1:]\n",
    "\n",
    "        self.posterior_variance = epsilon*t[:-1]*(t[1:] - t[:-1])/t[1:]\n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min=1e-20))\n",
    "\n",
    "        \n",
    "def sample_posterior(coefficients, x_0, x_t, t):\n",
    "    \n",
    "    def q_posterior(x_0, x_t, t):\n",
    "        mean = (\n",
    "            extract(coefficients.posterior_mean_coef1, t, x_t.shape) * x_0\n",
    "            + extract(coefficients.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        var = extract(coefficients.posterior_variance, t, x_t.shape)\n",
    "        log_var_clipped = extract(coefficients.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return mean, var, log_var_clipped\n",
    "    \n",
    "  \n",
    "    def p_sample(x_0, x_t, t):\n",
    "        mean, _, log_var = q_posterior(x_0, x_t, t)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 0).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * torch.exp(0.5 * log_var) * noise\n",
    "            \n",
    "    sample_x_pos = p_sample(x_0, x_t, t)\n",
    "    \n",
    "    return sample_x_pos\n",
    "\n",
    "def sample_from_model(coefficients, generator, n_time, x_init, T, opt, return_trajectory=False):\n",
    "    x = x_init\n",
    "    trajectory = [x]\n",
    "    x_0_pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in reversed(range(n_time)):\n",
    "            t = torch.full((x.size(0),), i, dtype=torch.int64).to(x.device)\n",
    "          \n",
    "            t_time = t\n",
    "            latent_z = torch.randn(x.size(0), opt.nz, device=x.device)\n",
    "            x_0 = generator(x, t_time, latent_z)\n",
    "            x_new = sample_posterior(coefficients, x_0, x, t)\n",
    "            x = x_new.detach()\n",
    "            \n",
    "            x_0_pred_list.append(x_0.detach())\n",
    "            trajectory.append(x)\n",
    "\n",
    "    if return_trajectory:\n",
    "        return x, x_0_pred_list, trajectory\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_random_colored_images(images, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    images = 0.5*(images + 1)\n",
    "    size = images.shape[0]\n",
    "    colored_images = []\n",
    "    hues = 360*np.random.rand(size)\n",
    "    \n",
    "    for V, H in zip(images, hues):\n",
    "        V_min = 0\n",
    "        \n",
    "        a = (V - V_min)*(H%60)/60\n",
    "        V_inc = a\n",
    "        V_dec = V - a\n",
    "        \n",
    "        colored_image = torch.zeros((3, V.shape[1], V.shape[2]))\n",
    "        H_i = round(H/60) % 6\n",
    "        \n",
    "        if H_i == 0:\n",
    "            colored_image[0] = V\n",
    "            colored_image[1] = V_inc\n",
    "            colored_image[2] = V_min\n",
    "        elif H_i == 1:\n",
    "            colored_image[0] = V_dec\n",
    "            colored_image[1] = V\n",
    "            colored_image[2] = V_min\n",
    "        elif H_i == 2:\n",
    "            colored_image[0] = V_min\n",
    "            colored_image[1] = V\n",
    "            colored_image[2] = V_inc\n",
    "        elif H_i == 3:\n",
    "            colored_image[0] = V_min\n",
    "            colored_image[1] = V_dec\n",
    "            colored_image[2] = V\n",
    "        elif H_i == 4:\n",
    "            colored_image[0] = V_inc\n",
    "            colored_image[1] = V_min\n",
    "            colored_image[2] = V\n",
    "        elif H_i == 5:\n",
    "            colored_image[0] = V\n",
    "            colored_image[1] = V_min\n",
    "            colored_image[2] = V_dec\n",
    "        \n",
    "        colored_images.append(colored_image)\n",
    "        \n",
    "    colored_images = torch.stack(colored_images, dim = 0)\n",
    "    colored_images = 2*colored_images - 1\n",
    "    \n",
    "    return colored_images\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def load_paired_colored_mnist_one_side(target_number=2, train=True, seed=None, dataset_size=None):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(lambda x: 2 * x - 1)\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.MNIST(\"./\", train=train, transform=transform, download=True)\n",
    "\n",
    "    digits = torch.stack(\n",
    "        [dataset[i][0] for i in range(len(dataset.targets)) if dataset.targets[i] == target_number],\n",
    "        dim=0\n",
    "    )\n",
    "    \n",
    "    digits = digits.reshape(-1, 1, 32, 32)\n",
    "\n",
    "    if dataset_size is not None:\n",
    "        if digits.shape[0] < dataset_size:\n",
    "            digits = digits.repeat([dataset_size // digits.shape[0] + 1, 1, 1, 1])[:dataset_size]\n",
    "\n",
    "    digits_colored = get_random_colored_images(digits, seed=seed)\n",
    "    \n",
    "    size = digits_colored.shape[0]\n",
    "    \n",
    "    dataset = TensorDataset(digits_colored, torch.zeros_like(digits_colored))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def load_paired_colored_mnist():\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(lambda x: 2 * x - 1)\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.MNIST(\"./\", train=True, transform=transform, download=True)\n",
    "    test_set = datasets.MNIST(\"./\", train=False, transform=transform, download=True)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    digits_2 = torch.stack(\n",
    "            [train_set[i][0] for i in range(len(train_set.targets)) if train_set.targets[i] == 2],\n",
    "            dim=0\n",
    "        )\n",
    "    digits_2 = digits_2.reshape(-1, 1, 32, 32)\n",
    "    digits_2_colored = get_random_colored_images(digits_2)\n",
    "    \n",
    "    digits_3 = torch.stack(\n",
    "            [train_set[i][0] for i in range(len(train_set.targets)) if train_set.targets[i] == 3],\n",
    "            dim=0\n",
    "        )\n",
    "    digits_3 = digits_3.reshape(-1, 1, 32, 32)\n",
    "    digits_3_colored = get_random_colored_images(digits_3)\n",
    "\n",
    "    size = min(digits_2_colored.shape[0], digits_3_colored.shape[0])\n",
    "    \n",
    "    dataset = TensorDataset(digits_2_colored[:size], digits_3_colored[:size])\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def load_prior_paired_colored_mnist(num_0=2, num_1=3, transform=None):\n",
    "    transform_ = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(lambda x: 2 * x - 1)\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.MNIST(\"./\", train=True, transform=transform_, download=True)\n",
    "    test_set = datasets.MNIST(\"./\", train=False, transform=transform_, download=True)\n",
    "\n",
    "    digits_0 = torch.stack(\n",
    "            [train_set[i][0] for i in range(len(train_set.targets)) if train_set.targets[i] == num_0],\n",
    "            dim=0\n",
    "        )\n",
    "    digits_0 = digits_0.reshape(-1, 1, 32, 32)\n",
    "    digits_0_colored = get_random_colored_images(digits_0)\n",
    "   \n",
    "    digits_1 = torch.stack(\n",
    "            [train_set[i][0] for i in range(len(train_set.targets)) if train_set.targets[i] == num_1],\n",
    "            dim=0\n",
    "        )\n",
    "    digits_1 = digits_1.reshape(-1, 1, 32, 32)\n",
    "    digits_1_colored = get_random_colored_images(digits_1)\n",
    "\n",
    "    if transform is not None:\n",
    "        digits_0_colored, digits_1_colored = transform(digits_0_colored, digits_1_colored)\n",
    "\n",
    "    size = min(digits_0_colored.shape[0], digits_1_colored.shape[0])\n",
    "    dataset = TensorDataset(digits_0_colored[:size], digits_1_colored[:size])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_paired_cifar(dataset, dataset_small, backwards = False, right_zero = False, transform = None):\n",
    "    imgs_high = torch.stack([ dataset[i][0] for i in range(len(dataset.targets)) ])\n",
    "    imgs_low = torch.stack([ dataset_small[i][0] for i in range(len(dataset_small.targets)) ])\n",
    "\n",
    "    if backwards:\n",
    "        imgs_high, imgs_low = imgs_low, imgs_high\n",
    "    \n",
    "    if right_zero:\n",
    "        imgs_low = torch.zeros_like(imgs_low)\n",
    "        \n",
    "    if transform is not None:\n",
    "        imgs_high, imgs_low = transform(imgs_high, imgs_low)\n",
    "    \n",
    "    dataset = TensorDataset(imgs_high, imgs_low)\n",
    "\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c551b3a-c660-44e5-ad5d-5a332954def8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display a few sample images in a line\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m show_images_in_line(images, labels)\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display a few sample images in a line\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[43mdataset\u001b[49m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)))\n\u001b[1;32m     11\u001b[0m show_images_in_line(images, labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def show_images_in_line(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images))\n",
    "    for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "        axes[idx].imshow(image.numpy()[0], cmap='gray')\n",
    "        axes[idx].set_title(f'Label: {label}')\n",
    "        axes[idx].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display a few sample images in a line\n",
    "images, labels = zip(*(dataset[i] for i in range(5)))\n",
    "show_images_in_line(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5181b8a-db43-4288-81c7-b82a48206587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAB/CAYAAACQeNq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXIElEQVR4nO2de6x0Z1X/18y5vu/bF5rWIkqgWsEACUQRKFZAFA2KYGokVP5QjIQYg0qI9YKJQAxREIoEMUIkaismYJCigiEaKYkxyMULSY1cRGpFDVJ6pe+5z/z+6O875zPfWc+z95zZc8552/1NJnvPvj63tdZ3reeyB+PxeBw9evTo0aNHj4c0hiedgB49evTo0aPHyaMnBD169OjRo0ePnhD06NGjR48ePXpC0KNHjx49evSInhD06NGjR48ePaInBD169OjRo0eP6AlBjx49evTo0SN6QtCjR48ePXr0iJ4Q9OjRo0ePHj3iIiAEt912WwwGg3jzm9/c2TM/+tGPxmAwiI9+9KOdPfOhhr5eTi/6ujmd6Ovl9KKvmwewFELwR3/0RzEYDOJTn/rUMh5/avDe9743vvM7vzPOnTsXl156aVxzzTXxkY985KSTVcRDoV7e8573xFOe8pTY3NyMK664Il72spfFHXfccdLJakRfN6cTD4V6Ib7/+78/BoNB/OzP/uxJJ6URD/a6+exnPxuvetWr4pprronNzc0YDAZx2223LfWdpz5CcFrxute9Ll7ykpfEox/96HjLW94Sr3/96+PJT35y/Pd///dJJ+0hi9/7vd+Ll7zkJXHZZZfFW97ylnj5y18e73nPe+K5z31ubG9vn3TyHtLo6+b04/3vf3987GMfO+lk9Pj/+NjHPhZve9vb4r777osnPOEJx/LO1WN5y4MM//AP/xC//uu/HjfccEO86lWvOunk9IiI3d3d+NVf/dV49rOfHX/zN38Tg8EgIiKuueaaeOELXxi///u/Hz/3cz93wql8aKKvm9OP7e3t+IVf+IX45V/+5XjNa15z0snpERE//MM/HHfffXecP38+3vzmN8e//Mu/LP2dJxYh2N3djde85jXxHd/xHfHwhz88zp07F8961rPilltuKd7z27/923HllVfGmTNn4ru/+7vj1ltvnbnmM5/5TLzoRS+Kyy67LDY3N+OpT31q/MVf/EVjei5cuBCf+cxnWoUw3/rWt8YjH/nIeOUrXxnj8Ti+9rWvNd5zseBirZdbb7017r777rjuuusmBici4gUveEFccskl8Z73vKfxXacdfd2cTlys9UL81m/9VoxGo7j++utb33Mx4GKum8suuyzOnz/feF2XODFCcO+998a73vWueM5znhNvfOMb43Wve1185Stfiec973kpE7rpppvibW97W7ziFa+IV7/61XHrrbfG937v98aXv/zlyTX/+q//Gs94xjPi3/7t3+JXfuVX4oYbbohz587FtddeGzfffHM1PZ/4xCfiCU94Qrz97W9vTPvf/u3fxtOe9rR429veFldccUWcP38+vuEbvqHVvacdF2u97OzsRETEmTNnZs6dOXMm/vmf/zlGo1GLEji96OvmdOJirRfh9ttvjze84Q3xxje+Ma2jixkXe90cO8ZLwB/+4R+OI2L8yU9+snjN/v7+eGdnZ+rYXXfdNf76r//68U/91E9Njn3xi18cR8T4zJkz4y996UuT4x//+MfHETF+1ateNTn23Oc+d/ykJz1pvL29PTk2Go3G11xzzfhxj3vc5Ngtt9wyjojxLbfcMnPsta99bTVvd9555zgixpdffvn4kksuGb/pTW8av/e97x3/wA/8wDgixu94xzuq958kHsz18pWvfGU8GAzGL3vZy6aOf+YznxlHxDgixnfccUf1GSeJvm5OZ908mOtFeNGLXjS+5pprJv8jYvyKV7yi1b0niYdC3QhvetObxhEx/uIXvzjXffPixCIEKysrsb6+HhERo9Eo7rzzztjf34+nPvWp8U//9E8z11977bXxqEc9avL/6U9/elx99dXxV3/1VxERceedd8ZHPvKRePGLXxz33Xdf3HHHHXHHHXfEV7/61Xje854Xn//856sD/p7znOfEeDyO173uddV0q3vgq1/9arzrXe+K66+/Pl784hfHhz70oXjiE58Yr3/96+ctilOFi7Vevu7rvi5e/OIXx4033hg33HBD/Md//Ef83d/9XVx33XWxtrYWERFbW1vzFsepQl83pxMXa71ERNxyyy3xZ3/2Z/HWt751vkxfJLiY6+YkcKKzDG688cZ48pOfHJubm3H55ZfHFVdcER/60Ifinnvumbn2cY973Myxb/3Wb51Mw/j3f//3GI/H8Wu/9mtxxRVXTP1e+9rXRkTE//3f/y2cZoXU1tbW4kUvetHk+HA4jOuuuy6+9KUvxe23377we04SF2O9RES8853vjOc///lx/fXXx7d8y7fEs5/97HjSk54UL3zhCyMi4pJLLunkPSeJvm5OJy7Getnf34+f//mfjx//8R+Ppz3taQs/77TiYqybk8KJzTJ497vfHT/5kz8Z1157bfziL/5iPOIRj4iVlZX4zd/8zfjCF74w9/PUB3n99dfH8573vPSaxz72sQulOSImg0guvfTSWFlZmTr3iEc8IiIi7rrrrnjMYx6z8LtOAhdrvUREPPzhD48///M/j9tvvz1uu+22uPLKK+PKK6+Ma665Jq644oq49NJLO3nPSaGvm9OJi7VebrrppvjsZz8b73znO2fmt993331x2223xSMe8Yg4e/bswu86KVysdXNSODFC8L73vS+uuuqqeP/73z818lgsy/H5z39+5tjnPve5+KZv+qaIiLjqqqsi4gHP/fu+7/u6T/D/x3A4jG/7tm+LT37yk7G7uzsJR0VE/M///E9ERFxxxRVLe/+ycbHWC/GYxzxmQsjuvvvu+Md//Mf40R/90WN59zLR183pxMVaL7fffnvs7e3Fd33Xd82cu+mmm+Kmm26Km2++Oa699tqlpWHZuFjr5qRwomMIIiLG4/Hk2Mc//vHiwhgf+MAHpvpmPvGJT8THP/7x+MEf/MGIeMA7f85znhPvfOc743//939n7v/KV75STc8800Guu+66ODg4iBtvvHFybHt7O/7kT/4knvjEJ8Y3fuM3Nj7jtOJirpcMr371q2N/f/9BsV5EXzenExdrvfzYj/1Y3HzzzTO/iIjnP//5cfPNN8fVV19dfcZpx8VaNyeFpUYI/uAP/iA+/OEPzxx/5StfGS94wQvi/e9/f/zIj/xI/NAP/VB88YtfjHe84x3xxCc+MZ3X/9jHPjae+cxnxs/8zM/Ezs5OvPWtb43LL788fumXfmlyze/+7u/GM5/5zHjSk54UL3/5y+Oqq66KL3/5y/Gxj30svvSlL8WnP/3pYlo/8YlPxPd8z/fEa1/72sYBHz/90z8d73rXu+IVr3hFfO5zn4vHPOYx8cd//Mfxn//5n/GXf/mX7QvohPBgrZc3vOENceutt8bVV18dq6ur8YEPfCD++q//Ol7/+tdfNH2kfd2cTjwY6+Xxj398PP7xj0/PffM3f/NFExl4MNZNRMQ999wTv/M7vxMREX//938fERFvf/vb49JLL41LL710OctLL2PqgqaDlH7/9V//NR6NRuPf+I3fGF955ZXjjY2N8bd/+7ePP/jBD45f+tKXjq+88srJszQd5E1vetP4hhtuGD/60Y8eb2xsjJ/1rGeNP/3pT8+8+wtf+ML4J37iJ8aPfOQjx2tra+NHPepR4xe84AXj973vfZNrupgO8uUvf3n80pe+dHzZZZeNNzY2xldfffX4wx/+8FGL7FjwYK+XD37wg+OnP/3p4/Pnz4/Pnj07fsYznjH+0z/900WK7NjQ183pxIO9XjLERTbt8MFaN0pT9mPau8RgPEYspUePHj169OjxkET/caMePXr06NGjR08IevTo0aNHjx49IejRo0ePHj16RE8IevTo0aNHjx7RE4IePXr06NGjR/SEoEePHj169OgRcyxMxGUfhfX19VhbW4u1tbU4f/58rK+vx+bmZpw/fz5WV1fjkksuiTNnzsTq6mpsbGzE6urqzLOGw+HkmL9D/0vH54HuGQ6Hk3cNh8PJ+1dWVqaOl9LItI7H48kKWAcHB5N1rg8ODuLg4GCyz+scWnhiEdxwww0zx5S34XAY6+vrMRwOY3V1dfJ1ufX19VhdXY3BYDDJexMGg0Gsra3FYDCI9fX12NjYiJWVlcl2bW0tNjc3Y2VlJVZXV2N1dTWGw2GsrKxMVgzT/To2Ho9jZ2cndnd3Y2dnJ+64447Y2tqKr33ta/HVr341dnd346677op77rkndnd34957742dnZ3Y29uLra2tODg4mNx7cHAQW1tbsbe3F6PRKPb392M0Gk3qxdE04/ZTn/pUY5nUcJwzevUutrVsf39/f1IuKseDg4PY2dmZnNvZ2Zm6l21I9T0cDieyr7aldqS6VvujrGVyPi8Wvb/0DJfv2jHXIxExpU/8vLYsG5aL6xiVPdsu64TpkV6VTOlcW7kWqPd4nz+ndF3EA19PXATvfve7G69xucrkzNu+HyOa7AzraG1tLVZWVmb0qnSdy0HW9llHnr4sX66/mvKW5fEpT3nKzLEMfYSgR48ePXr06NETgh49evTo0aNHTwh69OjRo0ePHrHAx43UB+J9gk19Vkfp/2OfyKL9h6PRaNKPN8896uNrQq3feFl9yv5cLyPvZ9L4h3nTxfv0rKyfuvTT/f7+tqj1+9YwHA6L4wgerGjTz5qdr9Urry31XbKOL0Y0tbGSvvMxBpl+zK5tevc8548Ti8jxou8tjRkoXdc0hqDNOyMesAOUjdFoFIPBYOo4bUX23lKZldI17/iBRdGaEGgwmqABZmtra5OBFPppkIUGUGSDidoY2JLx4nNY0DVQOA8ODmYG8RwcHEwGufG47lHFMN0lY8iBhBxsuCzUlD/LUPvMAwe5lBoVB5d52Wl/NBrFwcHB5HkaWKn2QEHR4BuVixsgps2Vqg9UU55qBHU8Hj+kSEGmMLT1dqp6029/fz/29vZmBhWqrFWWrAfVrSs+gYNw/dxJIXMKasad+20GFWbXZoMKS4P/soFuMjh+fyktlJllYBlkYHd3d+73NZEEGezaM2rlz7Y+Ho8nAwglCysrKxMZWF1dnehBnfMBhmoDLhf+7pJerw0kXLROWhMCjWQVBoPBxPBzlCUbKEdTzksGhMy75TkqmTaKhsZBysyJQlYRJAaefjU4b3ga4d5VZZXgho4ERg1OjVRGQPvutdcES3VO5UNjIWLIPJMcUWFy9H+tXPxdrvgyMuDn9Y6HAimokQFeQ2XppIAklkqPdSo50E+zaiKm6+QoEbnjQKaDmghBWyPs9/uMAr7fDTfbq+SU6XOiUHqm5+80kLA2qBGCGjKdTVl350PIiBfPue7RM0gIVldXp/SL7J7IAe2N9GPJXjXZsVp0rgt0RgiyqWbZVCNX1DW4EqMnIpAxt/VAZABpEHUfDWnpOSQF3tCkYEkGGFJaBjJhyEjP/v7+jEJTXmvP9nAXy0YEQdcpOkDvUtf6ORmKrHwypZxN32H6XRmTAGRM/MGKNhECEgESAk5L1D30giIODY7u0TW6nvWgOqd8OrE/CdQ8whohqE0rnIeoZvd7upxIZRECwaM2OuZ5cBxFJpZJqvf39+e6vmYQvb3zGNFknL1caYekX7nvUQPJiuSB0++d8GXbWp5PjBCcO3du6v9gcNhlsLKyMrXewPr6+qT7QAyKoRKHZ9y9bMHnlJciBFkhRxwKCBkalZNHNPhMP+cVIWXKUOxoNJowXnrNXWNvb2/qvysw5ZENc39/f8agurAwb3qeykHrEAyHw8l6FCsrK5N1CNbW1ibzdDc2NiZdS2LQmr8uIcpIgdIvIVIUQt1XyjfXOcg8L28DD9YoQeY9eB2qnY5Go9jb25us36B1CHZ2duLChQtTZFZGfWVlZXKvylHHdZ0iCU7Q3dsthUmPC94FqjTMa8R9n7Ln7Y/tNNMtNbi+8WeX0tOEeR2zZdfTvffe28lzMkdNx49CCLSV8zscDidtSLptMBhM2TrtU29ynYISkWR0p+ZAu33sAq0Jwfr6+swxFUTWdaBC8Mw3oUYGSh5PRHkxEUFKKeIwmuBegJRmtkgRxxiwwtjgPEIg74nnloGsy4CGVsdcmWTpycpW6XemzMbLUBnDy/SqZNB1vDaGIPPYyNZJdpyFewj7oYCMyPl/ljO9e0YGGCHgT3Wq+mVdKDIUcShn7jHpvU7CTwqlkHrJ4OuepvM1ZS5D4ufcIETkHp+TKr+nlK4mtNFLx1VnR+0ycLCttyEE3Ppx6hvJgvZJjGknpIPcDrILzbtfs/ZUi3ovw8E8MiEQWxIB8FWbGCFoYqwlBaZ9D7t7lCBiuvL030lCzRBmhCXzrgX3qhkZ4FZRA49udInsucy/wnAM+1I5CVlojWn3hq0Gv7+/P6l3GYf9/f2JcMgIjEajyTUSHhK1Uh6cBHgYWte596V723QbLEO4ulSgtfS1CZd6XWqfJGBvb29q1UdGCNhFwDqhMltbW5uSF5Z91t13kvBopRNPb3slxU29UiMEJc+9dE9JR2UGIotGzKNz+f4mHbXs+tve3p7reubP7YbyIr1NWSg9g8dYpu7hy9bpGPcZQVD9Ztfu7+/PtKdMrmr12DVaE4JLLrlk9mYQAi1NrJCuQia+jGnW5+GKmkZJlSnDqvNZCE0KKGPM+q8tDTqjA6wQjhXgbAldR+HhYCwtnev7yyIENW+YjJNjCLyRZZEOL28KhncJqK53d3cnBFFLGos8cHnPiAdIJj1KF9SMCJBxk6XTU+U4hYwUsJ1k772YUCIDEbkiJFHd29ubIgG7u7uxtbU16TLw6AC7a1Te9HhE+Nzj1b0eCSop8+NQflmXQWbsabAZ2mekq+Sh87k6nxny7Nq2uiJzZErvpjzzGurCWlTB29oy9FnbLoMs3xF1pyZiWle2aXNunBny9+4B6UXu67yWbCdhyJxmPsvJaIm4dIkjDyrUMWdO7DJwthoxPTBNaPLaPOTJCqfHmzV0GQy+t/Q+eqtuOOQZ+XuZLiq7kme2DLR9rrNeCb+n0cNrWbjXWS2Ng3cdKFqgcuT1TEMtzZmX5ayaY0McTuAWKcfTgjZRA2+bWShVdSSywJ/g3TGMiEUcTjvNyJbLBdN4XJ6PIzOibSIBmfcmkDDUSADf704Ln+Wg3skcHUeWBhn9UlRR1zThJJwbf3+JEJTauO7LiGnJ2KpNu+6XDlNZsi2TWGV6yYmXnCVdQ1tDhydrs10T6daE4OzZszPHyHA0kHB1dXXSvcDwSBaeFkoN0Y2UCp5T2ahonICo4FnAAtPjkQNWII2bQjxZmn0uNwduUdEuA7WRuSQ5flzw8Q/ZPkPBHiHY3d2dEMK9vb1J1EBdCRIefVBJxEGDEpkOppXKl16qytOjT1n4jeSRwvtgRBbtyCI/aouMEDBSoI9GMUIQEZNpVBHTxo8hVP2XImOUIovqnRQpaIoQUPaZr6NECPz5QuYw1dBECFyn1gyIRww8Tf684yLL999/f+trszxSH2ckIGuPpfoSOKaMNo/ePaOe/qEjRdZ0TOf5oSRu+QE46jallSgdPypaE4LNzc2p/1S6yoQKy79yR0JQY3a+pQCQFKj7IPM2SpEAr3Q3zhnTz1h7xvbU0KRE5RGTHMgLWwYWeS4JFomW8hFxWPZOCNg9oIau2QsiRCSFo9FoQhb39vYm12YKzY27CIHaFwmBCw6VesR8ns/FCDe2tV9GXEkGdnZ2Ynt7e4o40OB7O4iIibxLVqUISYKdXCitJ0UKSmMIGLotKWXqPd3L447M+cje2wQvP7/HjXZ2vkRUeL/rzhIZWIY8XbhwYe57Mg8+YnoNFLbDeSIEer62nCkiwy3ZGAwGE+dIBl/nZB/VpUAnWteKfKqesi8nMl109o6dEGQhLHr/mVLOGHGb0K0jY7ICw858j2/nKTA2lIsB8whmFrrNoi9ODnxsBsPD7i3KcItQiCD56HUXSs8H21C2VeSB/9nGfJ/RHx5XebRRyieBzPPXcZ7PwqRZ2J73exSI7SBbxIpG3vez87qfzyVpOwop6EIuS4abZNJJQkSkCpoGg8/J0t0mclACZ++UnpNFELLzmWednT9uEt3WuXGnzB20EgngYFkiaw9NDube3t5Uneg4n8dIkjs87HbgvWx7Ok+H16/18lgEC3UZUAlz7ACXLSaRcHIQ0b7BZcrPwUJxFq9jEe2n2einimEaeMyNm8ONT9fIhChLi+fb0y8F7kSAhEA/jjgXAeDofwmeupAkODs7OxHxALtWd4raEJURf4oy6D6lXd0SNEKKQEiI5OmyfnycxEkQP49uZfs8ll2TyYQrv8zg+y+LGOh/FiGIOIyWcTquIkQ6r/Sx/tjNE5FP+Wqqj42NjcbybULmRLSJECgfWZeBE4NSNMDRlF+erxGCzNCV3s9rqcsyUuDdesvE1tZW4zXeZjxCQFmImB5cq/bpurxUB6xL2jRGdXiMUc+NjY0YDAYTXeddBupyZVQ961KoRQgy+VkER/6WgRJBQuCeWleshahFCwTvx3OPpIkYMOrgStfz0yQgXmnLYNylsQlNxiUzJL52Ar3FrF6Hw+Fk7XsaCzXyiOnuARoaGmNn0BH5gEI9Q+9QnWifypuKjB6snuUKsGs01XXNyPt1Xm++5ViJUnTA67v284GFnIWjSA+nI3I6KbvIOEuIZCCTpa77Q2uYJ0Lg5IB6junNjhFH0YcZqWi6tq2OoR7kvScZKfBF1hyZAfRuR5cHjxbwnD+LcEdO+ptOjBwZDpaWQY+Iqdk1eh7ti3QaI2k6T33m3djLIgcLLV2cCQ0JASuKmFcJ0yBEzFYkjYWzeo7eFFw58pl8LgU8UxbMC48xKsHGsyxkhCAzrn4sI1eZp8ayz8pSAqG00BjICHNsAYmBogtKB+uE9SpCSgFTfa+vr09FCFz4GMlwY6i8LNvzcWTELNvnMaaxdg+jH1lbbwNXsDTs8nZ0nrImokAHgdMVa8u2Zm0vw5kzZ1rno4RMPryP3pGRhYjZroJ58tIGbfWH2nnp2lL9exdbW1KwDAenzcDrtsTRDb+jKf1Z94vLIoklow0qT4/EeHSSEQKRaREKDWJ3J5t5z0jAIl2frQlBTQjVkGgQS0ac17dRwrouY+MsBA7A4PzPjBBkipKNx9mn3pcZRQoRQ6osEz0/m7rZBZpW9yqRspJAsH5KSjBillDQkK+sPLAmwWj0wPLNGjSzu7s72WoADg236kbPiHigDtjtQM/UR8OrrXBAJLsVJHQeJVoGYSspG5ZbyXvXdU3HMkJbijLwfsK9DC8LlSHfK3K3u7s7mV2ipctVRypzkQGtS6FQqb/b01PCwx72sOr5Nii1+1KUytPGcDHLjco4M1xHaWdt75HBiSgvVlYikTR4LhOcpbVsuWkbIaD+93Jn+gjlNyM7NdD+uPPEiIHe4dNvOfuK3QsalM0oAG0Wu95LhMDLZdH6aG2haqzD2bIbkKOyyDYeBEN4XngeOva0uFL1/mRvdKVyyIwmvYYmZb0o5u220D2lvJSUZbYfMc2aPfRVC0d7eKxkrGRcpLgoQDI+7DLg8YjpOpAxkycyDzntAq6QMzJQIwneXmsGoI2n0KRIaCwYafHpWyRvWZeBdz+QPM6b5mXAHQFHqYshIidSrjuaFHWJpPl+E6inmkhBaZ/GzB05pXVZMlOLELC83UMvpaUpKjIP1Eb4bi8L6j8RA0Gy610G7DaQPKns5fjUZpeoTLogBQt9yyBLDBOUJbDmNTV5q6oATveR4GVLRjJUGXHYCFjwHGTiHhef7/sUPFWc/vN9qlgq0a7RxKo9DzpWY9EeJRC4zzrRdRxUJsO8u7s78Qr39vZiMBhM5sCzLnzwn9KqboLhcDi1dgG7HyQ0EkLWtRi6R29IYpSfLlHy1N3407iyfbJsatc6VNfML4lgCVk963qtcklyQsLNLiHJoyA5lOxm3Wg1nbEMeDnQsJS6DRi69X2l2SMGOl5DRkZqhMCNDJ/DrY+A9/bgkQF/HmWfMq7/yyAFtVkG7iV79FjHMizanjwyEHFIkD0NKieOV/Ip0hGzs/To0OqYO7ylPB2VQDo6IQSOGjOtJdaNsu7zfRo1FSLXQWCXgZbH5XM4/Y2GwaepuAFt6schnCiMRqN0YGYXqBECJzJU1Jmn76D3nnk6LigSBk7JkfEvEQIaMNa/d2uILVMg+eNUR6Xbuwf0LF1P5VjrPz4KsvJ0I++G3mcG8JcRhsywZQSWIU2XL2/TmZGQrGjsh7+T5ExkXM/TV1HH4/HU4MOSoVs2GcjAdqg0uJ4pOQa6h7Oq5ol01PLbFGlg9ItjCNzTVPoyguBpcL1Fw5uRgi5RIgT+btaDe+yeH53LnuloijSUzjMt3m4iprueVUfZuDuSA7c585DGo2KhdQgED4l7QZOZZhXWJozOBsFG4fOByax8GWVVmI/YJLMmSeBzM6WZKVbts3F6frtGU5iN6fIIiMPrqCRghAuk2DH70kq/jAjwfVTCMtra+r7qzrsMPNrj9duUv6OiqV2r3LIuglK0wEmE1z29iohDpddExh3ZtaWIEstUM0oiDgnbYDD9ue3SiOk2be2kUCJOJR2hY7y/1B5q3T0lspbBdQ7hZVu6judVrx4l5HVdo+RM8jjJSsRhe8r0UBfpdPvmtqv0bqZfYPifaSQJ8HyRnGbP7BJHXqkwIh/0FDGr6GQgItr1pwluyLLwPEeaK0rgyyhTaEej0VSEQB4Zp42wvzpTAK7IPF9ueJcNH1ToaZahLCmokrCzDEp1Ro+TkZXBYDCZjqhV8JhWDSp0L53EgPPbZfAjplfG46BEeaVaijcipqZLql41sFHhbZ+bvEx4FwDbodoeF3Si8ScJ0L57eZQJDrRV+dbymNW1pzdL+2AwmNSlBh+vr69PKTbVn+rLowGZTC0TXg4qHzfcWahWx7PQr7ZOxEvv1bNKZFjbJhnk9aoT1rffWyKIjDKwnl2Hssy6RDZA2svSyZd75e44UneU6rOJSDVFCDy9Qs3pyKJ5tahUhq7lZaF1CDIlUQpJeUXJsLftV8+MrYdXGBlQ14FGtzszZrjVBYn7TQrLK3wZYbQmZGVIAY6YzjeVRdZgeVz5KXmH2rLudY8UJcP67Gum4SNrZnpYB5rvrmeqa0jLKJOE6LlSbJxHrwV0POrQtXBlSqbk/ZciAE5cSR5EGFRWEYeRPFcyi+aP6dKgQUYAGHnT1M+1tbXY2dmZ1I+vFcF0CyfVbdDWsLly9jED1EdtCEGNlGf318LcHqHLdGYTVEclEuD/u66nWhRK72b0gvfxP9sR78+IVRsy4Omqkes2pMHTknXvZeeXjYVnGdDAZPAIQsbMtWWfcRam8n4t9lVubm5OiICmN2kaVMYmpWDVwGggGIptCtV4Y6kx+eOCG/lSY8tGrjIvbvBLx0gwSNZ0zn+exlIenMRFHBq8tbW1CaFQJOjg4GBqrIuIhurIFRnHGywDGVHjOBVGp7J9RrLcCDshUJ7YdSKyQ6UoIsb3kcyXSIx3U+j9/KS2SAEjQxo7oClWLldNhHtZyHRL6Se58TadeXFZW6dsZYa/pBNLMuRwZ4yRjpIuzerayYnLMttVyUlYFFn+XJ+1IUrZdSWj6s9pioCUnN7adRn8vV6/GTFYNhYaQyAh8EgBC5UNr1R49GKyc7wmYnoOsDzGjY2Nice4ubk5iRCQEEhpaWlWLo6jvk8qyVKa3Sh62dD7duHqOsTGMiKoyGQoOIKVHx0qseaSwnCSR+9Rx/V8vtPflRGNTNj9etU/V8jT/4gHCIIGL7LLQIpRholGtesBhRF5+JORALVD7dPIqk2SEJAw6Fp6gsq7L33KwX5ck0FdK5QH1jlJAtPBpY05XkAyzLalNA2Hw8laBSIHEfX6XiayQdLe3aL/WRSSskW9RHnz9p61MZezjEBn0QadYySJ0S5GQNkNx/dmOs7lkMZR8iRZWgYpKOkypsGNJ8uH5zi+zAfqMb8sC5ZrE5FyncdruCWy8mpDVI4LR44QkCWSFJQyUfIshRoLcoOSEQIaIH5Zil0GasgetmSa2OBpfDJiQxbuyAS4Vj5do+S5uMdTKvfsmNehM2geLymx0rOzd7vyY1uTco6YHt0t48f18/klRhIInWckoUtkwi9FnUUIaOSzaAHPkzBk5UZlRln1mRnsiqhFCPjT+/U8GQqd49gMjeXgrJOsy6Bt2+gKWVSIU78yw+NGiOnNvLkS2XZQN/B5JBr+LH8mya9H7iJmjZN7+zrmaffneZq7jq5lz2OaamSgRKKya7L31rpBnPyUiFAbB9jrwkl9hlpXUZc48tJ5bgwE7wOVIssSL+HTvrasyExIfdDUcDicGlSoLoO1tbWpaYdSlIwGcOvHqPwYNnUFmjWAkne9DPjHXtzwy2DSe/QpmWxwNCQZQ44of0GMxlaf+jxz5kycOXMm1tfXY2NjI9bX16fqi4PfmAb/HzG9bjlnMSgdereMksiBogKKHshQyaipnXaJ7e3tmbIjIXBP2yNVjCB4hIDHCH5eld9bV12TiGxtbcX29vbEcPN93rYzGeAYAtXRcDiM3d3dSd0oTYPB4VTUnZ2dGa+otL8sZIOkaYTZJv1DRrWuguxZJaNZCnO7QcsieXwXu5PUHiiTHiHIIgg8zuso79QLrN8uUZre7mXpnn4WpXE96PexbZMg6b9sE7u5VD7cZ/mWbJ1QI90OPoekrem+RdCaENSE1BUIw4u+8I97B1lF0/jzO9FSbr40sRQexxDoOl+HYDQaTZbUzUK1rnyzT/ZKcVJBlsJ1x4GMEIhEOSFQecpwkGzVPHoRwFK4jIYi4pAQrKysxNmzZ+Ps2bOxtrYWm5ubk3rxL3xlefBjHrWhMKp9aXyBSADD5isrK1MLJXmdd4ns2+6MDqgdagngiAe6GZQWnXcSwGiBp1nlrnLl2hwqP6Vha2tr8j5t2d5rZIDyQe90MBjE9vb21NgFzSzY2dmZWick0ynHFSkoEQKXnYjZ5ctpnEsktmTcM8cn84D5fhICN4IeaSJJlyHjccoKx7O4URS4z/Mil10j+5Ily9inmXsduC7LCAGJjeeLM8xUPtIdynOpbbo+Kl3jqHU3tCUXXRGDThfXdwNJRSKoQDOPQAKnSmNfJL0dN2o6xq4CHnNCoC3Jiq5hCNQ9UZIA3actK4cN0EO6y4gUZExd5aJyJDGgwiEByxQa3+EN170R1j+jETRMrGO929m+kAme0kEF6V0GXgb0ZL3LgILfdd2UBhX6FEJ2E8g4y+D7GAOS1BqJkYIjOWU0xbsPeLzkxUTkayYIJAoRMUVeJIdMS0TzILJlIfuuiDsqmfEvpddlRcd9W/L0PfqQRUcjcoPHZ4ug6Zgblizqw2d52NyJDet7GfVUGsuTGXn/r32/hvpY+zTsJc/fdV7pWMR8uqPWlVAiAhlJy+pyUXRGCDyETIXDxLJR0TBwESF59fIkSxEAekP0OP1+Nlx6+KVBhTwv5czzMjJSymSWETGTZzU+Cl+XyLwdGlqty0Cy5N0HTULm6faoQI0QnDt3bjLoUxECdR0oTW0+/ETCRZYvpan6UN2tra1NtpqFoClwGk9w3BECyga9crUzDfRThIDttBQtEFivJNGMEKjM+C6PVniEwEmEz3jwOlL96HnD4QMDCiXLHHDoOK4Iwblz54rnSobfjYobTSe7uieLFPiiM05CnLw7SWBd+mwUj2hm3QeMKPBDYNRjJBROLlTPXZPoTJdlToobfJ53cuaEgOlmWURMf69D17NrUsgiLtpmeiRzeIjsfidxWfTAjy1aH50RAm94rjDcgy41djfyMhYbGxsTZccxAowGcFAhCUNGCNQI5HnR4FM5choXPSyRgojpD1ow/OQNY1lKrjRiWmUqw6syZXnJa3YmnSk15oHKhXWuLccGyPizq4CDQOnhCyXGyzTS22e+KeCqK0YC1FVAj7tJYI+CbJYBvfKdnZ3J+3d2diZtr4kQ+CwEgt0v3i3DPJI80ZBQZj2y5wqQyss9R9Wn5CEiJuVcigjx/mVjnqXYHbVogZNnjwpkAxZ9BDzry3Ull4SW4ZKOojFjBFTnKbO+GJd7mtRjjHa6LHVdV77eTZsoyzwRGZcBXs+ISRZZy+BGuXZdCbzP9Srrg2nM3t0FKTjyGIK2IUVnO64ISAbY1y2j5eMBVldXp6YV0sBlXrATAjVqCZCEZWVlZSYCwDEB9P7pFTlrpCKkke3a+yS8TN1ToeH1fnsP2zshyLwh5S+LELDfzbtzREKyKYmeh4wQsA5Uzi4ITgioCFl3UmpSosdJCBghkIHnp6K530QI2BYHg+nvqUvxqw6oOHWO6ckMfC1U6USQeWQ0jATutBCCeSJS3Pcon0fWBPf8PQKg/Ne68TgGKCMEnlYabkYl1QYYAci8Tf2XHvPBdB7dXYZOy+olK1+Wpa7JtrrWIwlej26vqLepx+nUEjWDXGvPfl8mW76fEYKa3M6DhWYZeIFqSwUs5UVDwme40dJIdBn+M2fOxMrKymSU+traWpw5c2Zi7J0QUPlxWiLTyQhBNstAilgLq8ib0/HBYDDZV5481KT8tWGZi8LDbDTyKlMaZpIleiNUVuxGYB9mKULAeh+NRlMGX90Fiu6o3hhCpoFnXXkDV9qktMbjw0FrSpfSojpSvg8OHphlIM/cuwwWDbc5si4DGvbt7e1JZIptjtGCbCEhptlD9k70SMpcMWb1x+MEr1EalHYqLKXX5U/vr5EBV9LLxCWXXDJzzAmR/5zoROSDB93blwxlY2gofyQH0meK4Hl50qulPltbW5siv6oT6mQ5QIqOOolmm1LeGY1TGdBAdoVSl0GJEJTO+73e5ljPfi+nIXu0IdPhbrTVxaD7Su2axtyj6tSnGTnQfVk75bPnxVIjBBSwEigYGUNmN4B+ihQwglCbhcC004hLWCUUEgyyYS5wQ8bMBqNrlWcdc5KwDC80YpZVZwpI5UMD4V0GTgLomSj9KkspFpWlN2C+nxGBLDJA4fbIgJMsP5Z5bEqf0jEajSZtgiP0ZbjYD98lsudyjAOnHXKsCscTeIQgW7iIUPmpXj30S+Xo0S3enykYP6bjJIKSISoxhrZL0RimZVlyQrjM0DBKMTP8zv1aOj1MTUKdRQucvFPmKD+MEDgh8DQyXWwPNE4k1DRMlHc6My6TyyJuWZmWIgE8XgMdGoH1SX2ufR83UNvPbKGe24Sa3JUiBBkhyLoUjoLWhOAoL/EwDQWEg8novWrgmbxJ9X/Ts1QEgYMGyajVTZARAhoeXe+EQAohIqYiBxIYKVoxZxkWCpbyzG3XbFrQB2VY7vQuON+f5eX9y7wvG9Tk3qUr/owQDAaDqb5sdu24F8X010iAkPVTR0yHTzMBk9ArvT44rytk6xBwDAHXAFBUgJEoTkH0qMBodDjzgOXCQYUkX+wayQhBBpIXEhM/xnwxvMyQq9YgaGtMlk0KfMxKxPRqi2pvvk9HQul0B8bL3iMA/Ek+/B6ed0IQMR2pc0LghI2kmSTAyUQWxXXCLS95WRHPLHLjNkT7bSIEEfmgaObfB2V6Nxoj3ZwKLDvAruc2TrCnwcP93KfdYXlktuRYIwSlBLSBkwFv4DJU6hIQIdjc3JyMF9jc3Jw5L9LAsJozameHbMz0nlTBJALaciwBCUHE4ahUKWdFE46LDEREnD17dqa8aXSz8RUeIaBiO2qEQOVIo0tSwugN3+8eAJWwys4VM+/JWDHrlsciYjJehJGf4+gyUPlI8ZQIgXcZsEsjW85Yz1beXL5U3k4ICFeaTCsjGT6egWFpGVQqaP+vYxEnN+Uwojzt0Nsa27jatNKpMvaZO3RQWPZyeCJiaqBvtq4KiTLlxImMdBLD1N7mGSHgeeoqtjHKl+6VwYs4HKS4qDeaISMEEbPTCZV+b2sZSB4Ej2zVFv5i219fX5+U087OzqTt65sd3o3nhIrHSaZ1jOez/04OsuuPJUKQJaCEEoujcnAv0Zlx5kFm/501zptWT7f/6OXUfowu1JTaMlh19iVKDzm6wqLB9/Bl6bzKKIN7HawnPicjAI4SA+b52n8dc281Ytaj8/R3iSzq4N41f+6VkKhwMJj3MSr9yje7rURolX+RW5ab7nEoHR6yzP57dEx1nIXY/f2O4+gyaENGXL4p2xnpYXun/HnXGaMBIhQ6xi4Bj9CVyFzJg/Y8ZMfY9UkvV/nyyAjbT8k4LYJMl2WGP/vPfDucSLENMzLECIH0h0gTIz3seuY7nTzxfdl/d3pch/J6v4dRmq4cz9aEIFMYTCQrRw2YhaUK2djYmHj9GxsbkwGCGjSofZ33ueoednRFxMpRZXqas3C3G4SScNGYjMeHswrYSKlEaNyWQQYiIs6fPz9zzMcPKN1Zd0pGvnw8gXt5o9FoKnJCpUEPwz0fvsvLimXURtG4IDqk6FQGo9FoEp6loZPh7RoeIaBHcnBwEFtbW5N37+zsTKIFCktyPQwfIEYPPvMklEdFvRTW9CmWNUXKd2sgJgc6SnkqLS5rbd5TUuZNBHRRzOMkqE2rzfO4opvD4eE06eFwOOnWXFnJB/UyaqfzJOEubwKNAA03DXsNNOjMo+pQ++oKdQKq5y8rQnDZZZfNHMt0arbPa/3+UoSAbdcJQbYYGMf1+EqjvN9tC6MA+mXrR3CMkE8Ldpnn/SRvi9RLJ10GbkhV+GJ7NDbq95fB15oCPlddxovhNG8EngY2WDXsTECyUDf33bCTndP70s89B26PAz6GIGKaENBTySIEVEI85pEZgt0iJARsoE4unHS4QReRICnI6pB1VAIVucgAPSK9x/uEu0RpDAGViBRAaR0CKgzeT1LrhMC9OZUjI12OzPNk5MK/u8A0MJKgNETkBNjlI1Pkqjde1zVq+kxp8PKiZ8ioG428j3niuB3puMHgcFwNnR3KhqfJPUmWreuqkjHwMtbz3HlzmfPoJw1p13Dnhu1F8qs0UW8xAjgPIYiYbuds29kXSEWMSQj0HRASBnc8SZxVhyIRui9i+iNgikowgkHyItKvuis5t/NgYUKQhQTZ2NzoMJzG0ef8z2Mlr9LTwfR5iF+QsGS/Evw5Lnx+zIXJ39E1o47I1/9meam/lBEW90aysL5HCLKyYb6obDIylUVRjqLwm4iA0kCjkoXMJWxNivSo0AeUBEYkOMtACmU8nv0MN7sQeH9E2UtzBT8YDBoXBfJnUPnQ6DsRYITC9UHp+V5H3m48ZH0a4F6py4nrM667wQhCbeVVPSciDyG748Lyy3RRKR8CyTejmU4wdR/Jc5toxFHQ9I0Jjzxmxz2fJUJA713yxTE6MtIkBCKFjL6tra1NxhN4ZMUJM49FHC4Qtr6+PuUIkazQ8fL063qStUW6chbqMsjIQERMeZeqDDFgdRmoa0DdA+fOnZsw7M3NzZkQHEfgssHXvBDuZySi9p/CLuHjvvqJSILc2yHj9tBul3j4wx8+c6xmjEmyKEzOtGus2xmwtj7oKmJ2QZquyEDmCSi9EgoKDpUfw2xZ6L0LfO1rX5v6zzJTGF5hQfc2fGwBDUIWHdCWSj4jfJlyLIGKUhEMD496BMNJQUa8nQB4+6u1u+OC0kLlmsmQBjbLsKs7VB/z0iBodQ2oq0BLePN+ygQNBwmi6p2LUpFEkOBmJMEjASLI+uk/655p4fUl8rcILr/88plj1BvUI1k0s5Z3h9qjh+a9e06kXfKpaxQt8G4+yq+eybUidJzdD3IIdIxROV3r0QqRE+ky6oajYiFC4PAKcQ+NkYAsUsCV7Hh9zaMUM8pYbZa2tsiMjbNRf6Y3wgzLIAXZMqxMX2YMONAsy0/GvpkHlftweDhwjXXh5VUT2EXg91NxuPfjpI1h0GWMIahFCCTcUgYcwe99mCRc7IusCX/WFmnY2iDrFmDI04mJj5am0SDhcoMkI8Z0qX7apnUZYDti2mmEvGvO9Zl/dE3RAF+si0YtIqaMQcRh1FPGgGTFiQvTT1l0r571kEWanMTpGZSbrvVZm0+5+z6nTbMMncg5SAgkq6Vph+wS4IwarQwqB1H1T4OudNKgqwyZNtX17u7ulGNVisRRNrIIyFGw8LcMvCFJWHRMGfOBNQqlafCN+td0nMLFSi95qxkhyCIY3lhqhiljmc5SGTUo3e/p6ho+7dDTXgrVu/GPmP2Ai45ReWib9StmBroUjcjeSWXHY7X68WN8rgSHbTLrd+NKbF3BxxDo3TWvW95GREx54B42jsj7kznCmaSu1I0mZHknGZBCpMJ0suDkhWnjGAOvH7ULXc/26KPDjwve7rzc1Ka5zof0mSIA/KCXdJwIwZkzZyZ6UFFSGl1OOVU5aaqsR4lqTkqWL88PZZpkX2lhZIIys4wIwcMe9rCZY65vGZ2RvVE78UiLO0IC88xBg1k3HT18EgJNG66NARKZ4NgDnR8OhzPjcvb29iayoPyIMDP640SRzsYiRK2zCEHJsErBixB4lwH3RQ5ICNyQeF9RZvxrXgnvzQQpY98UEJISNkQJq3dpeFksA5kQEZmX6MqjaZ9GOmKaEGRGi+/2kJ+XT1ZeGSnwPPFavkvXk6ixbhkWpWfbNe6///6ZYxwLUAozylvJugsicg9coOfA8it5SyxXf5aXkRSOj4L2iEFpUBXTE5Gv4++GeFkyU3uup8FH5osIyMHhN1Y0a0pf+FxfX4+zZ89O9Jq6D3xWFddFEFlU5EizQ3Z3dyeGgeXpOkp5yPKVtQPqPkZ7vO4lP03RqUWQzTJgZI9TNDljytsR89Wkj5lXhuQZ8pfB5mwgzryR8Ve9iTBIzrmv8xpv4F0GOsbzIgZ6N0mCopskGScWISBKjTDr//EwG8+X+oT8+ZkC09aVaGYQ+Qx6Iq6Es3DaaUKTR+DG149n55uemz0volmBO1nwYxnBy55JhU0j2PT+LN8cPd4lsme6V50ZUSrlpoiA4OVGL0J55PnS/fzvUQCXCxJCypzLnxuQjJTSUKk+F/F0mjDvc2syxF+m41zX+U8hZ6atdL+WUtd11Hm+zfaVbhKIkh4oORF+bZfIIkK0B4wYZzOmuDJtFuEk6CzSK6dDqLqQPDHSJgKhZ7F7aTAYTL6fouso88qXR9D8mMgoSb7yrHdrn47bUetnoVkGTYZGUP+ZtpxNkI0foOftz6OyZLoyBeVKyNmxCjbicNlS7bMPyAd4cUt2qXSUCMSyFNxRmHoWOSkRsMyrZB5ZziVjRUEqvY/p4j7fld2v95Y8AaYvIyQRywlN+9cOvV0yDM+25tP6mG6SjJpMugco5eGh01rbcQ9fW67iSXnMyI0rxBoJ1bOoiEn8ukQbOazJa4kIuGPT9JO+Y4RA3SbUSRFR1D/yYDkWhVPhPJqQGUD99+gTdW0pCtglSk5liWxJh5MoZESnRGTUztROua9uREVp1H5V3oPB4Vof3j3JMQY65wRd9cyuIKVVZS5SoPIXSCo8mrOIvCwUIaCwstDdmCvExgE3JcFgV0EJ7jFFTIdXXSkJ3lBYyQxLeXhUSttJgPelZl4WsSxW3da7zbyGkuDUBhX6s7Kwtl/b5G3Unl9Kq4cGI3JvIKsbYVl1EpF//pjtReMG2M4UMoyYXunQFTWPEe4dtfXosmdl3QGSBeUli2ZkXQY6nqXH64zEgYarSzTJTE3/REzrEjoYNLgccNhEEvg+fyZB0kUyICLgx6m7ZOyYFr0ji0KVZHxZZCCi/nGjEgHzgZ1Z26/JgcrGdYyO6dkkVe5IyojrGSQYETFD8g8ODqY+SU4Z4n18dzZOR+kVeVlUny1ECLICz/qmMsPixlnw0Fd2jv8zhZUpJDckYv86R5ZMxedCViMFWdj3OEhBZni8jLy89J9pknBFzE710TGBhj97JpFFaQhXhnxORjA8XVndZmXg0YeaYV0GMkXrbZfXRkyPh+G5UvlQOXk5eHnVyljHdS4jAd7OKW/ZT+9sS/6WbXxqkJHI4PnKykT6QE4HnYyIw35reoN8t886yba+z7EoGnMQcWiMJB9uAGWA3MFSndPZ8nbQNTJdxvEBTGvEdFsWsXEy1YYQkNiyDtmuqetL7bsGvjsjxE58mPYS8dT9jEosEu1ceAwBE6jEecIZISgxYgoUlVlW8dry5wND9KxsOpl7v0w3G8L+/v7MYJDRaDQZXaoBJQr/cjAKw3R6/rKE6I477kiPO7vPGnJEzDQsCZ9PrVLZZe8QyKL57AzZuSbC1DZCMA/xWpbRcUPrCqYW/qVy4rNqZMDRNkpQInM1Q6fzDCtTFv28G3rmxZV6LU1dIdMLXk4uHwSNufLL6WsaACgDpi6B8fhwrQ5NWeOxiJjoGA1gu//++ye6SMtdb21tTc5vbW1NCIDOb29vT+kmlW2TfCuN7uyw7tkmusZdd9019d/TzHVp+NEon42me7VtKwPU0ZQ9lYXsgOwDZbekX2vI7JDaggYVRhzaLLUXdlXIFrG9HRWdEALue+ZICjKykFVQpgxciUQchv1YOc7k3COLmO5v9rTqvJ5ZY+SlbgMKTq28usLW1lZ63AU3U+bKu7b+8RWSuVJUJ8O8Rpn3tTnHLp6mCFXb53eNTGFmniXrJfO4+awstEuwTEr9ibqmptCzNNY84hLhdNmj0ecxf68b5a6R5V3tJUtjdi/zzX5ijyqqbmWEx+Px1OBAORqCzsvJ0Jb7mp7K8QIc7a5R8CSW8qC19QgBoTS517xsQrCzszNzjORFhlBpYjidXSIR5XFtJYPp+XE5ZBsv2Rhvr7X2yygN00nbyGtoQ5ledp0oKnVUuemky8Az49GBjAxkypoVUPIUMmGU8fYBTM5oBScBnh4+U/NLKYDZClOMUCzbu3Hcd9996XF6bL5PI8TGl7FufsrVPXNuS8eYnux/1o4yONOvdUE5YciuKaWzK2T1TyXCNqpzbEe8Rs+jIs6MLWWnlL82hEDnM2JQOt6GGFCu2xCBZdVPLe9tQs5uLFh3g8FgMhBtMBhMzTuXAeNAMQ/zHhw8MH1te3t7si9dpKluigAocqAIAc9vb29PGS9GALlsN40oyyfrMsi6RbuEfxAsYnqWgdZx8G9I+MfTWFfz6imHE4EaGciIcBt7wMgZ7ZPercWO1M5Ub+PxeDIGT7KvQYpHQWtCkL3Ala+UNKcRMjzFEJWuEViIaqAU2qzgWSHqOyMhEEP3CnHSwmNs9N4l4AtOSGicRdcY4zJw9913T/33MnKCFBFTngvriQtI8Wtt2QCpjASWiF5tW/Po/bzXl/93MurXZWSQ7+gSmdFx46H/7ObiMRIC3h8x220m1BRgCVk79XZUIwGla/UcHSu9l1snCstAjRDIeEbMRpx03McCREyvea8IAA2x8sZnqCuB/eKj0WiqS+DChQsTQnDhwoU4ODiICxcuTHUpOIkgIeCgQs7jJzlwI0pninrWj3WNe+65Z+aYZJn6id+I0GJ3EYfrFHh7z/5nEcbMsaC8cWEuXy+kRJYzQlDSmxyQLwPPOhmNRrG2tjZ5tsqGNstt5zxYuMug5KVREXsB17xAgZWgbclbKf2yfh1PZ+aJkFhkAwiz/jVVBtOaldUy4ANxvJz4wQ5GP8Qk9VP/lJQT8+QMnHVYm5FQU/glI1YSZm9PavhZ+5IXxnrWVgKUpXeZyAyjG/hMqehczQuhAsg8oybDehRCwPRl6cyeq3qonctksmu0KQ8adKXH068yYJeBdx+ojZKQS3EzmsCyc73jXZY8JvLIY3JgIg4HFVJ2I2JKRlR/jB6RBDghUD66hi/3rTRR1n0WG2WfW6GkUzInxvWL63Tq0YijfQaaz62lM5PjkiPGQYXj8fSYlHnQycJETCg9M0YCPEqQkQUqGP3PlBAbpUcI6FkxpM9G7IWqPDANup4fteAX6UgaPO1ZA2mjlI8KH4jjpCn7sIYTgoiYLL06HA6n9rWaJD0Mr+eM4TI9NWPG67M6cYIZUa5DHmdbYzv09PO5XaLE0j0CwHbkhJbdPS4HpfL08vP9DG0IgY61ISz+XB3PjGopHfMq2nlQMjwRs+2O9UhjHzE9LocRSfWFr66uxs7OzmS2gQhpxOGgQhlmlumFCxcmOkeDBre3tycRgq2trUlXwYULFyaD3e6///4YjUZTEQLpLQ3KGwymuwEZIeB0uhohcF3dFbIIAe2GloZml8Hu7m7aZSA0EQLXZa4zBMmpkz0n8U6IS23Y9VYWTRLUTkhAJUdqoySwR5WbIxOCEnvxrgOGe9y7dDKgrSufiLwfiwqTn42lAfSQfsnYCCVjKtY9Hh9+xzpT0G3KrGt4l0FEvkSuyoOEIOJQEfLLbFp3fWVlJXZ3d6cWlvJuA9VtxHS0gJ5I5lFmpCDz2LMIRNaGnJg6GfV9LmKyDEKQeQFZ6NUJrnuHXm6lfUdGDGrIjHOm5LL3ZyQgezZJQWb8nTgvixBk5UWiIrC90YvOvH7qCDojVPJ8JuvXCcHOzs7EyG9vb08GCXqXgGYZaIyTzqvLgcSTIXeRERIC/VQ+2VgW6sZlkAIfD0UjvbLywEqNkmE5LNJPlGl/RnaMzkU2mNqdBspoKYKSEQJu+X69W+1O+76NiKn2xvEEAiOjHoWcBwuNIci8NB7XfSWFVPImhCxM6YNavFJKFcUCbEpb6ZlZejKFWCuzZSAzPG5cfJESKS8KxmBw+DU1TnnhoCN2J7inlynTiHz6WRtCQEWcRQayPkASAtUNF+0gw+a9y+rOcZSIY+ZRZNum8wI9cR2vyaHf3yYttWc1oaYX/HnLkKOmdLIvlm1FitmVv5M3dgkwMqnuAUUopPgpwyTs2aJDlGnqqKxrk7pL6Wd70PuVFuWXulM6wfVtm3KcF9l00MxIap9y69EnHne480DPmp467VtmU7zuSxGETPdFNK/rkdm8zP6pnLg9CloTgqxPIusmaPLglGBmTIZIoGfpBp0FlPWxsVLI2J1R6T3eWNjYFSHQM/l8XqOyYLkwH8smBqWv6jEqoDLReAOuiKf06jPKPuJZAqOwZ1bXfszT4uVFwRJqz2zqKsjuZyTAowKliFWX8PbmJDMjnBmJJfH0qIAbJidorvwz1AiBtiQHJRLcRhEtq6znRanLgOmjkXBj42W7uro6kS0NFJQXfnBwMImuKcK2t7c3aZf8wp1+W1tbExnN1hlQl4EGEyqCoFkG2mebo1ElSZZsR+RdBoyCeJvrGtkHwbzLQOmvzTJg22VbY51RT0g/sCslGy+lclFZaOtRPula6V9FaX1AOomc6wTd49f6uBHeS7t6FCw8y8AVc0nQ3UhGxJSCyTx4NkQPX7Gh8njpp+va5KvG/Fjpfk+Wz+NQfhmr9sWZ3HvgIiokM2tra1MEaDQaTcJxEq6akc48be8LL9UJjXhGCPz5tQgBnyWFLM+H3Viely6RGcyM9WfRJt5b89L9J7gBqynvmmdRe3ctr45MHk6SFGTppQy73NKLdFImedLAroiYiQBQX1C/0RBTPrimgC9+xuiA77uDFHGoCyJiRnep7TvpycYQKM2LGJwmlFYq9MXRlA6P+tEhKbVn3Zd1b0tXiOR5W2Dduz5zO8S68mtcbjNb5frbbRIJRFdjOzqJELhSdWFiJMCFiR6oe6xNEYLsXFbgTEcTShVG1EhPFh1ZtuLLns9RpzR2qgeeUxrJjvWjULj3z2fVokBsxCR4WVdHZqSzgaiebzc4fIaPIcgIwTLqqCSYJQ+7BPfuqbjdA8qiJm2eX0pPZvgpE22Ihr+r9suuWQaytqf30WC4p0lSzPYvEq3jEQ/UM6cVeqRM7ZJdcipbjRugwSdJrxmXpjpRPqg7lX+hFBVguS0jQuDOjZMn2hDmRTqIskz5cxLNtuXjihghoC7x8mZZOUGkE3lwcDATaY6IKbLg5z2aUBsYrvu66MZpTQj4Na6I2b5XKu9SFID3suIyT1P3sCFmjCxjSzVhYZpKyO7XfaV7vfG4R7tM5ZaRNb07Y/RSZE5g1tfXJ4OO1tfXJwSBy4RGTM/N1fMiZkmA9ksMNxN+EgGG92tdElnemdZs0KOToWWQgszoeDdBU9vMDDwNUi2knW3bwtPjIe3S+ewZnp+SnFBePP9dI4uqCZ4u5tFlWmUhmZBxlxHQoFyRa7VpzTzgyH9hPB5PugtkGGQUOMg5W4BNbaoGGlBv/ySH7nBF5Ev7dgmPELCd0IMfDodT5eryTPLC9url4zpH3RBu29xJdWSy4Y6vO6yM7GhGiNaWGI1GU/s+UD5i+oNJHOfBd8+L1oQgC6l6I+I1LsgZi1VmyLap1Nwol0Krfl7namhi0U1MOyuPkrfDc8cFvpdkTXnKlLCH6LOoTxaScyIQMS0E3tfFRuxppsFWW6B30LYMPcLA7gM9xwcNdV0/bZh67RrJQ9Nx91x5PNu2Qendbc83Pbu2v+zoQER96WL3mJkOGn7Jk64XGXBjRCMl8uCeLvWJe4rZWJPMSWlTHyKRrL9M17ne9euWQQay53rUgpEUXq9uBLcduiYjNAKjAXwHp1CTEGTlnJULj7EMnShkepGkT+TS9aYTAj3/RCIEQs0DVuYzReWCEnFYmBRMnfMMe6SgRBycJZYKLDNumQB6+lkOblBpdHTfMpDVDckWSQDT7URAhpOfqh4OhzNTDfkOKS9nqmKyJARs7GrkBPvyBoPZAYBMa0RzPzbzly1m4vnvGq7cGNVSeqnwmwTZ5Yhee40IlI41oWR0MiOUKcLsWU5UnZAdF2nOIgSUC+otla/qi8ZBpJcG3vuifXVA92p9dT3KjNqLh57VneB91Lo/qwOmXddFTEeylIbMiB4HMaitD8FBza5js8i0R014zPW5O0J8r+8rz2wHWXr17AzUmxoQqqiAugr4gSp+Kj0jh1k05ChoTQi0NGRbUIhcYVGIIqa/O63/EdMFnbFiFko2roDXNwmMX5uxY8KjAN5Aj5MQNHUZRBz2YdJLIZmTkuLXxNiXJtLhjN37NtWAOcODhIAKrUQIfJRvEyFwY+Teshse5nmZKHUZuHKqgemlzLgnmxncbOv7NTBtLh9+PIsaZc/LogBNv2WgiRBkRkHtkLrER+srAkWDr+m93rZ95gvfR5Loip9E0klD2yiB59vbqnuyrg91TdfIBhVKfvf399MuxYzQs6y8+9J1Ou/N9HWpHWbHvBtSx/y4dKC2PjtEC1GJHGjGiNu4Glk7ChbqMiCavAL30Mmmta0p+Mw4e+ZdGbk3U7vHry+9z5E1muNWbrXG6uXr3k9EvV+dpMHflRG0bBZDtookPxfNNGvRDe8yUJoZ7ix5sM7gqTCahLxL1ASzRDQJGvrS/+we36+Rg6OAslpLC+FkQNtlk+Vaekog0fJIAaNufl4kg3Ilhe3OkZ7Fds7yKEU3M++w5Ny0KQNvUywDNzKZXu4apbQIJGAqb85A4D0+0yoinwIdMbvscZPM+H/XNR5x8K5Q5ZU60x0sn1XC+nYn1x3go2LhLgPBG48nzhsvPQoJlo9JyO7ncWdLWYio6efPy4gAzzPtmcdZawjLQu3ZrAcqNs2RZtpLc3s1uJDlwDLnlyA1Z3p/f39qpbQsguDeAEOpikqIJPigTRcAKk+O2lb+vE25R7YMZBECb59ZWyWyCEGmxJuIwFFJQRPJ1tYVHbe+L3jkxrsfl0naap6o0iAZznQU004Z10wDPssJt3eNNXWH+THJL40JIwQ1Y019ymPZOzICsOwIQfb544hDOSXpKrURpZOrRuo+9sXXHLwSvI3qGPdVt9KlGjjKyKvSMh6Pp1ag3Nramiw/ff/9909FCNyGZlHzRbHQtEMhUwRUWr71ilQhZ16Ejntj1PFsakyN0ZZIQYm4eB4FV8D+834uettdI3suvRAOJmRe6HXrOdkSv0x7VqbsDlA0gJ9idULgiyQRmuXghIDTt5g3pUn7tdHjx42St1Nqe01wEl27hvsub02RhSwPTYTAPWdeq+dnMlSLQC0TrksipstV0wF5HXWg55Ny74SAnqzO+cyZiPKH3zL59q5SpaOpLblujpheiTQz+CUisAxCkNULj2ftxPv3nRBk0/NoOzJ4283qJKs3dgvJqfKPximdWVRAi0xpX/oyIwQ1An5UdNJlkDVIV1qZ10/DLQaeeUAZ62UjbTL0mXH3YyXm2+TlKK1Z+vhfeVsGsrrR+weD6aVTVW6ZN+Zz9V3BZYSMdUg27gMJOXKWx1hG8rAYAVCa2Z6Yluz9Oi4cl5HpAiXD7fsl4e+aELSFdyO4/DeRmKb0dY3M8FAmSun17k3KP7vjvL3yHRkhZwRCz61tMx2WOSVyCLI1STzfbcqqRBK6QtMzs/LQuA3qARpbN77e7VIC9Y4TENZVVq4qd0WMRELYjeTp8KnZWXqVLqaP6V0UrQnB5ubm1H83vmLBWR8bwQZdCluVGDGv9TR4n1p2TYkwZHnK3uP7HgWhN+7PqinxRZEN+PRpTzSWatAqUykkdhmQ6TJyEDHbPSQSoK4DMVp+bU0Egd0I2ZxjKq42XQZUAp7vGsM/DXCDXToWMR1F07ZkFErPX2aEwNu8t/dShMDfe1ykIJNFyoO2LuM03J5Plyflg3qNEYhsjEs2Fdbbvqef73IjRZLCvB2lnFjvyyADR30unUh2G0u/cBYGv1TrzkObvGXdSqwbdcUqmsQxD7w34nCAMccLaJuNIchkrmscOUJAZRwxvTKeK+Jawl2oMhLBa32bGV+/vgmlMQOlY7qHSqH0zppn1BWy51MRZJ61G47az70WIjPMJGfOdp0Zs7yGw+mZEJkhY8TA3630tFUqPs7guNAkE67EBcpKLb0lcjEvISi9z4/XDD8dgCbjX9qeNLK0lyIF7uln99Cb1f54fPiRI/c4/T6mS3DZ9me0KcusTR53HRyFEJAkuT6gka85haXoZ+2dtFWcEim9558sZjp8m+m0Evn2dHaJhaYdMvEsAHqgmbEVMg+hlEEvGN/PCjYD31l7V+09+q/8qRFwSpI8AA8LLkPASusQZIJBJZYZ3QxO7ErGQ9smMpUhqzeF26g8GSHwe5VvhzNzT7+f7woZiWa40cO5HjJmKLTU/h014zqvoa0Zfeap6T+fVXtXbds1SiSabcy9at7jnqK22aCzLEKQEe+I2cVwPC2eBt/KI2W9kXg3yST1hTxoLsCkZ2ZdiF2gbQQjc2ioA5yIUhe7bZqnS8T1uP/3aGZm3zLHSfnQ8xSh5YJJmbN56ggBw2TKpBoQR3d6g8xYd40N1Yy0p6VGBkoKy1FjkV6JrGRVJr0F97S7hhMCNzxkslkZZ8Yy8yqzfT6H+6UunAxZGWdl34a8ZPB7MqH2clgGmH7WkdqLe4WuiCOao2K1usyuqSGTUR335/DapvNZeWQGdJn1UZs1Re+aoX03+MyD7muSGzfyTgayboSsjLK0Kk8k/xH1gayuK33MDok6dR2ff1xoIrtu/Hmf8iECHjEbTWwqm4jytESd4y8jBrQVHB/AtLK7wfUo0TUZiFhwUCErwhubjJAv71nzFGoeUM0D5bVZBTe9tw2cZWeK2BtS5hksA5mipRdaUyi8p+SReKPPBKVtNKAtMYg4ZPosz8xwZHlhegn3ArM8doVS2NiVlyIBTD/LOSvzWnpr5TNPPksy0yRLi8ha1paPC67sm0LuTcdK5Kz27uyaNkRJhpyOgMtk5kz5zImsnWVRnkX1aQlN9d3GQfFjIgFukyKmCVDEdHTBy9DTl5EDEjTqUifMJW8/I5CltJxohGBjYyNNjLMdrvHNwV/e3+ueIH8lg1OLEnAKSZeFxLR7qCdiOlzHff+S3rKMTkS7LgO9m5GMzLPhta7QmvJQaugeGit5kEqfp6HNj9dqPxNM7i97FcmSB+VkzcuABIGEzsuopBC6NKpUZkfdMm9NaeXxZZKB0uqeEeUpZbymJD9+7KjnM93BNHnbcYdLOijTr6V2pPukTzMC4KRj2ch0EI87eaNeprGXt62tri3pq6OCOiVbTpnP9lUm+YyIQ71OJ8LTemKEIBMgGsmIw0pQBsXIlGleT9YW0RxiLkUGap7pooXFCmT6WHk8n5WRr6G/DJSUmxQySYB7ErpWW84sKBneJpTInddXZiy8jnmtK0VXlsqX54n3Z2srLDuCQ9BjoKfCuvCxJ04KSl0JQtd5aWv0lQ4/z2f4c7P0Zoq/a2TPbeofLkWUasTUPcYSYc22/vyIQ1n3hcJ0DRfu8W9m8HrKine3OjHNHItljSHI6qVGBJQWlqXSS0KkvFOH+/osusYxD0nIxp5o6zrRuwIoKyR0JVJ9ooQg66em0PN/RD5X3A15qVHNEyFo8paIJm8lexevZ4PKlJsEMFOUEcvrc2vyRN2Ylgx8G+XL55TeeRTUiB3fzTbHLg4PxfMZ3gXC+5bp5dS6DJQWz19G2Njv6YrQFfU8aWlC1g/r/zND3+Y8rzsJeHlkHmfJ8PtzStdk0YUm8kNZrZFxf6e2JSOnAc90wqjHWE+u70rG+LgjBP6/ROhJniNmlyimPWpDCErOXk1P8X1OmLnvz8h0NMmfP+fECMH6+vrMMWdbYpqMCnCupXcV6BkkFR5eFjKWViIJJSXjDbrEBvm8LF1ZPliBHk5zT6Br+IBPppvRGs2RJVHw9DX9sny4cGXMt8Sys3t13KMLrjCzVRVpiDIFy0E//h36rhVcadyN8iaD7p6MyoHXcsAYFXXWlo/azjLl5KSA15aIb5vzfF6tnS1LZrK6ceKYHcuUfXZttnYA780GnHn3Y3be00IZIyHI5E/6wOXRB9npOr2Ts31qstwFsvqulbuXsfJbQmYvsvN+LLM92Tbbd7lxm+Iyxu6NWvfMMupg4ZUKS16AG1SGTZq8hqyy3Dj4ddovsbEMiyhON2Binmqc9Nx80FjXyFh01pc273iGjACo7pbhHZTIGM9lRKZEDJnmknJdJlkrGcrsvO+zDWWRtCwqUntvDRmRbiM7NVlukvEmLFNeIuqDpLNrPD2lCEMJNSLB8xkpqaXT23RGFKmrav3R3Hqa2O3YtVfqeSsdc3kt6bJaXTS18dKxTNdkXXYso4wM87psnJfntaZrl1EXC88yUKZcsWaEwEPYWWE1eZO8zo9x2wV8TEMpfVl6XaiP29tR+jPvq+S5NAlZU/rdwy11rzQ9o1TebvyYv7YERV7UPPnqEq5knTyWvHIqeyE7dtQ0ZSSKcvtgQ83wRJTXGfDrXYnz3kyWMv2XPaP2TL6f8uBEIGJ2yXS1fX6/gGRb8sauhyxNx90uMvKU1UuNxDWhFvnIbI/KKyLS7mKPImfPKelGlnEpH13IvmMhQsCMcwEFneNPiljeco0M+HGeLx1zuGAsArK5kufK9zLc1qRUuoD3b2V59jCkp6VGGuYxml4n85a/kwBtndwozYyAtPEMGBnIZoJ0idoYAuWLYWLvr/VjPoWX71hUOZfy7qSg5PFcbCjlt0SSs/NtDH7pnL+D5/35NRIhnVvSpzTyPKf71AZJurPnextYVr03EbVa2fJ87Vk121A65oaf12bd3nqXR1V4fjw+7MIhfPxQk43rEp3EfTP2pv1lGcKmBjmvZzrPe5qiF7yuRGK6Sl8GL+tSdKd0/WlAk7AeJSJU8x5Ougyk+E8bTrpcThJd5n3eLoZ5UHpWWxnPZKEpfaexXcyb5pITlN1HclZ6bhOZcTTpriZH5dQSgh49evTo0aPHxY2eEPTo0aNHjx49ekLQo0ePHj169IgYjC/WUUE9evTo0aNHj87QRwh69OjRo0ePHj0h6NGjR48ePXr0hKBHjx49evToET0h6NGjR48ePXpETwh69OjRo0ePHtETgh49evTo0aNH9ISgR48ePXr06BE9IejRo0ePHj16RE8IevTo0aNHjx4R8f8AK4XG5AvCq28AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images_in_line(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images))\n",
    "    for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "        axes[idx].imshow(image.numpy()[0], cmap='gray')\n",
    "        axes[idx].set_title(f'Label: {label}')\n",
    "        axes[idx].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display a few sample images in a line\n",
    "images, labels = zip(*(dataset_small[i] for i in range(5)))\n",
    "show_images_in_line(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df853c",
   "metadata": {},
   "source": [
    "## Loading config with DDGAN base parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04060075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('ddgan parameters')\n",
    "parser.add_argument('--seed', type=int, default=1024,\n",
    "                    help='seed used for initialization')\n",
    "\n",
    "parser.add_argument('--plan', type=str, default='ind',\n",
    "                    help='Init type')\n",
    "\n",
    "parser.add_argument('--resume', action='store_true',default=False)\n",
    "\n",
    "parser.add_argument('--image_size', type=int, default=32,\n",
    "                        help='size of image')\n",
    "parser.add_argument('--num_channels', type=int, default=3,\n",
    "                        help='channel of image')\n",
    "parser.add_argument('--centered', action='store_false', default=True,\n",
    "                        help='-1,1 scale')\n",
    "\n",
    "parser.add_argument('--posterior', type=str, default='ddpm',\n",
    "                    help='type of posterior to use')\n",
    "\n",
    "# ddpm prior\n",
    "parser.add_argument('--use_geometric', action='store_true',default=False)\n",
    "parser.add_argument('--beta_min', type=float, default= 0.1,\n",
    "                        help='beta_min for diffusion')\n",
    "parser.add_argument('--beta_max', type=float, default=20.,\n",
    "                        help='beta_max for diffusion')\n",
    "\n",
    "# brownian bridge prior\n",
    "parser.add_argument('--epsilon', type=float, default=1.0,\n",
    "                        help='variance of brownian bridge')\n",
    "\n",
    "parser.add_argument('--num_channels_dae', type=int, default=128,\n",
    "                        help='number of initial channels in denosing model')\n",
    "parser.add_argument('--n_mlp', type=int, default=3,\n",
    "                        help='number of mlp layers for z')\n",
    "parser.add_argument('--ch_mult', nargs='+', type=int,\n",
    "                        help='channel multiplier')\n",
    "parser.add_argument('--num_res_blocks', type=int, default=2,\n",
    "                        help='number of resnet blocks per scale')\n",
    "parser.add_argument('--attn_resolutions', default=(16,),\n",
    "                        help='resolution of applying attention')\n",
    "parser.add_argument('--dropout', type=float, default=0.,\n",
    "                        help='drop-out rate')\n",
    "parser.add_argument('--resamp_with_conv', action='store_false', default=True,\n",
    "                        help='always up/down sampling with conv')\n",
    "parser.add_argument('--conditional', action='store_false', default=True,\n",
    "                        help='noise conditional')\n",
    "parser.add_argument('--fir', action='store_false', default=True,\n",
    "                        help='FIR')\n",
    "parser.add_argument('--fir_kernel', default=[1, 3, 3, 1],\n",
    "                        help='FIR kernel')\n",
    "parser.add_argument('--skip_rescale', action='store_false', default=True,\n",
    "                        help='skip rescale')\n",
    "parser.add_argument('--resblock_type', default='biggan',\n",
    "                        help='tyle of resnet block, choice in biggan and ddpm')\n",
    "parser.add_argument('--progressive', type=str, default='none', choices=['none', 'output_skip', 'residual'],\n",
    "                        help='progressive type for output')\n",
    "parser.add_argument('--progressive_input', type=str, default='residual', choices=['none', 'input_skip', 'residual'],\n",
    "                    help='progressive type for input')\n",
    "parser.add_argument('--progressive_combine', type=str, default='sum', choices=['sum', 'cat'],\n",
    "                    help='progressive combine method.')\n",
    "\n",
    "parser.add_argument('--embedding_type', type=str, default='positional', choices=['positional', 'fourier'],\n",
    "                    help='type of time embedding')\n",
    "parser.add_argument('--fourier_scale', type=float, default=16.,\n",
    "                        help='scale of fourier transform')\n",
    "parser.add_argument('--not_use_tanh', action='store_true',default=False)\n",
    "\n",
    "#geenrator and training\n",
    "parser.add_argument('--exp', default='experiment_cifar_default', help='name of experiment')\n",
    "parser.add_argument('--dataset', default='cifar10', help='name of dataset')\n",
    "parser.add_argument('--nz', type=int, default=100)\n",
    "parser.add_argument('--num_timesteps', type=int, default=4)\n",
    "\n",
    "parser.add_argument('--z_emb_dim', type=int, default=256)\n",
    "parser.add_argument('--t_emb_dim', type=int, default=256)\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='input batch size')\n",
    "parser.add_argument('--num_epoch', type=int, default=1200)\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "\n",
    "parser.add_argument('--lr_g', type=float, default=1.5e-4, help='learning rate g')\n",
    "parser.add_argument('--lr_d', type=float, default=1e-4, help='learning rate d')\n",
    "parser.add_argument('--beta1', type=float, default=0.5,\n",
    "                        help='beta1 for adam')\n",
    "parser.add_argument('--beta2', type=float, default=0.9,\n",
    "                        help='beta2 for adam')\n",
    "parser.add_argument('--no_lr_decay',action='store_true', default=False)\n",
    "\n",
    "parser.add_argument('--use_ema', action='store_true', default=False,\n",
    "                        help='use EMA or not')\n",
    "parser.add_argument('--ema_decay', type=float, default=0.9999, help='decay rate for EMA')\n",
    "\n",
    "parser.add_argument('--r1_gamma', type=float, default=0.05, help='coef for r1 reg')\n",
    "parser.add_argument('--lazy_reg', type=int, default=None,\n",
    "                    help='lazy regulariation.')\n",
    "\n",
    "parser.add_argument('--save_content', action='store_true',default=False)\n",
    "parser.add_argument('--save_content_every', type=int, default=50, help='save content for resuming every x epochs')\n",
    "parser.add_argument('--save_ckpt_every', type=int, default=25, help='save ckpt every x epochs')\n",
    "\n",
    "###ddp\n",
    "parser.add_argument('--num_proc_node', type=int, default=1,\n",
    "                    help='The number of nodes in multi node env.')\n",
    "parser.add_argument('--num_process_per_node', type=int, default=1,\n",
    "                    help='number of gpus')\n",
    "parser.add_argument('--node_rank', type=int, default=0,\n",
    "                    help='The index of node.')\n",
    "parser.add_argument('--local_rank', type=int, default=0,\n",
    "                    help='rank of process in the node')\n",
    "parser.add_argument('--master_address', type=str, default='127.0.0.1',\n",
    "                    help='address for master')\n",
    "\n",
    "cli_params  = f'--plan {plan} --dataset cifar10 --num_timesteps {T} --exp ddgan_colored_mnist --num_channels 3 --num_channels_dae 128 --num_res_blocks 2 --batch_size 64 --num_epoch 1800 --ngf 64 --nz 100 --z_emb_dim 256 --n_mlp 4 --embedding_type positional --r1_gamma 0.02 --lr_d 1.25e-4 --lr_g 1.6e-4 --lazy_reg 15 --num_process_per_node 1 --ch_mult 1 2 2 2 --save_content --posterior brownian_bridge --epsilon {eps}'\n",
    "\n",
    "args = parser.parse_args(cli_params.split(' '))\n",
    "print(args.plan)\n",
    "\n",
    "args.world_size = args.num_proc_node * args.num_process_per_node\n",
    "size = args.num_process_per_node\n",
    "\n",
    "# if not args.use_ema:\n",
    "#     args.ema_decay = 0\n",
    "    \n",
    "if ema_decay > 0:\n",
    "    args.use_ema = True\n",
    "args.ema_decay = ema_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d611de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train(rank=0, gpu=0, args=args)\n",
    "\n",
    "rank = 0\n",
    "gpu = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a2938-2c44-49c0-b481-f6fc67482d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac33b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "NCSNpp, nz = 100, z_emb_dim = 256, num_channels_dae = 128, ch_mult = [1, 2, 2, 2], n_mlp = 4, num_res_blocks = 2, attn_resolutions = (16,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from score_sde.models.discriminator import Discriminator_small, Discriminator_large\n",
    "from score_sde.models.ncsnpp_generator_adagn import NCSNpp\n",
    "\n",
    "torch.manual_seed(args.seed + rank)\n",
    "torch.cuda.manual_seed(args.seed + rank)\n",
    "torch.cuda.manual_seed_all(args.seed + rank)\n",
    "device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "nz = args.nz #latent dimension\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    dataset_ = CIFAR10('./data', train=True, transform=transforms.Compose([\n",
    "                    transforms.Resize(32),\n",
    "                    #transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]), download=True)\n",
    "\n",
    "    dataset_small_ = CIFAR10('./data', train=True, transform=transforms.Compose([\n",
    "                    transforms.Resize(8),\n",
    "                    transforms.Resize(32),\n",
    "                    #transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]), download=True)\n",
    "\n",
    "\n",
    "elif args.dataset == 'stackmnist':\n",
    "    train_transform, valid_transform = _data_transforms_stacked_mnist()\n",
    "    dataset = StackedMNIST(root='./data', train=True, download=False, transform=train_transform)\n",
    "\n",
    "elif args.dataset == 'lsun':\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "                    transforms.Resize(args.image_size),\n",
    "                    transforms.CenterCrop(args.image_size),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "                ])\n",
    "\n",
    "    train_data = LSUN(root='/datasets/LSUN/', classes=['church_outdoor_train'], transform=train_transform)\n",
    "    subset = list(range(0, 120000))\n",
    "    dataset = torch.utils.data.Subset(train_data, subset)\n",
    "\n",
    "\n",
    "elif args.dataset == 'celeba_256':\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.Resize(args.image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "        ])\n",
    "    dataset = LMDBDataset(root='/datasets/celeba-lmdb/', name='celeba', train=True, transform=train_transform)\n",
    "\n",
    "elif args.dataset == 'paired_colored_mnist':\n",
    "    # insert my dataset\n",
    "    dataset = load_paired_colored_mnist()\n",
    "\n",
    "\n",
    "dataset = load_paired_cifar(dataset_, dataset_small_)\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "                                                                num_replicas=args.world_size,\n",
    "                                                                rank=rank)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=4,\n",
    "                                           pin_memory=True,\n",
    "                                           sampler=train_sampler,\n",
    "                                           drop_last = True)\n",
    "def inverse_color(dataset_0, dataset_1):\n",
    "    return dataset_0, -dataset_1\n",
    "\n",
    "#if args.plan == 'inv_color':\n",
    "#    prior_dataset = load_prior_paired_colored_mnist(7, 3, inverse_color)\n",
    "#else:\n",
    "#    prior_dataset = load_prior_paired_colored_mnist(2, 3)\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    prior_dataset = load_paired_cifar(dataset_, dataset_small_, backwards = (args.plan == 'inv_color'))\n",
    "\n",
    "prior_data_loader = torch.utils.data.DataLoader(prior_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=4,\n",
    "                                           pin_memory=True,\n",
    "                                           sampler=train_sampler,\n",
    "                                           drop_last = True)\n",
    "\n",
    "netG = NCSNpp(args).to(device)\n",
    "\n",
    "\n",
    "#ddp\n",
    "# netG = nn.parallel.DistributedDataParallel(netG, device_ids=[gpu])\n",
    "# netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "\n",
    "exp = args.exp\n",
    "parent_dir = \"./saved_info/dd_gan/{}\".format(args.dataset)\n",
    "\n",
    "exp_path = os.path.join(parent_dir,exp)\n",
    "if rank == 0:\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.makedirs(exp_path)\n",
    "        #copy_source('BMGAN', exp_path)\n",
    "        shutil.copytree('score_sde/models', os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "\n",
    "coeff = Diffusion_Coefficients(args, device)\n",
    "\n",
    "if args.posterior == \"brownian_bridge\":\n",
    "    pos_coeff = BrownianPosterior_Coefficients(args, device)\n",
    "else:\n",
    "    raise ValueError('ONLY Brownian Bridge posterior')\n",
    "\n",
    "T = get_time_schedule(args, device)\n",
    "\n",
    "if args.resume:\n",
    "    checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    init_epoch = checkpoint['epoch']\n",
    "    epoch = init_epoch\n",
    "    netG.load_state_dict(checkpoint['netG_dict'])\n",
    "    # load G\n",
    "\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "    schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "    # load D\n",
    "    netD.load_state_dict(checkpoint['netD_dict'])\n",
    "    optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "    schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "    global_step = checkpoint['global_step']\n",
    "    print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "else:\n",
    "    global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19069825",
   "metadata": {},
   "source": [
    "# Markovian Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d47a188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BasePrior:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class WienerPrior(BasePrior):\n",
    "    def __init__(self, eps: float = 1):\n",
    "        self.eps = eps\n",
    "\n",
    "    @torch.no_grad()    \n",
    "    def sample(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + math.sqrt(self.eps) * torch.randn_like(x)\n",
    "    \n",
    "class CondLoaderSampler():\n",
    "    def __init__(self, loader, plan='ind', reverse=False):\n",
    "        self.loader = loader\n",
    "        self.reverse = reverse\n",
    "        self.plan = plan\n",
    "        self.it = iter(self.loader)\n",
    "        self.brown_prior = WienerPrior(args.epsilon)\n",
    "\n",
    "        \n",
    "    def sample(self, size=5):\n",
    "        assert size <= self.loader.batch_size\n",
    "        try:\n",
    "            if self.plan == 'ind' or self.plan == 'inv_color':\n",
    "                batch_x, batch_y = next(self.it)\n",
    "            elif self.plan == 'id':\n",
    "                batch_x, _ = next(self.it)\n",
    "                batch_y = batch_x\n",
    "            elif self.plan == 'aid':\n",
    "                batch_x, _ = next(self.it)\n",
    "                batch_y = -batch_x\n",
    "            elif self.plan == 'ind_id':\n",
    "                batch_x, _ = next(self.it)\n",
    "                batch_y, _ = next(self.it)\n",
    "            elif self.plan == 'ipf':\n",
    "                if self.reverse:\n",
    "                    _, batch_y = next(self.it)\n",
    "                    batch_x = self.brown_prior.sample(batch_y)\n",
    "                    batch_x = (batch_x - batch_x.min(dim=0)) / (batch_x.max(dim=0)- batch_x.min(dim=0))\n",
    "                else:\n",
    "                    batch_x, _ = next(self.it)\n",
    "                    batch_y = self.brown_prior.sample(batch_x)\n",
    "        except StopIteration:\n",
    "            self.it = iter(self.loader)\n",
    "            return self.sample(size)\n",
    "        except RuntimeError:\n",
    "            self.it = iter(self.loader)\n",
    "            return self.sample(size)\n",
    "        if len(batch_x) < size:\n",
    "            return self.sample(size)\n",
    "            \n",
    "        if self.reverse:\n",
    "            return batch_x[:size], batch_y[:size]\n",
    "        \n",
    "        return batch_y[:size], batch_x[:size]\n",
    "    \n",
    "class OTSampler():\n",
    "    def __init__(self, loader):\n",
    "        self.loader = loader\n",
    "        self.ot_plan_sampler = OTPlanSampler('exact')\n",
    "\n",
    "    def sample(self, size=5):\n",
    "        x, y = self.loader.sample(size=size)\n",
    "        return self.ot_plan_sampler.sample_plan(x, y)\n",
    "        \n",
    "\n",
    "class XSampler():\n",
    "    def __init__(self, sampler: CondLoaderSampler):\n",
    "        self.sampler = sampler\n",
    "        \n",
    "    def sample(self, size=5):\n",
    "        return self.sampler.sample(size)[0]\n",
    "    \n",
    "        \n",
    "class ModelCondSampler:\n",
    "    def __init__(self, sampler: XSampler, model_sample_fn, ema_g):\n",
    "        self.model_sample_fn = model_sample_fn\n",
    "        self.sampler = sampler\n",
    "        self.ema_g = ema_g\n",
    "        \n",
    "    def sample(self, size=5):\n",
    "        sample_x = self.sampler.sample(size)\n",
    "        \n",
    "        with self.ema_g.average_parameters():\n",
    "            sample_y = self.model_sample_fn(sample_x)\n",
    "        return sample_x, sample_y\n",
    "\n",
    "bmgan_sample_fn = lambda y: sample_from_model(pos_coeff, netG_proj, args.num_timesteps, y, T, args, return_trajectory=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d1f806e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './saved_info/dd_gan/cifar10/ddgan_colored_mnist/26:10:24_17:29:18eps=1\\\\T=4\\\\mini_batch_OT=False\\\\D_opt_steps=2\\\\ema_decay=0.99\\\\ipmf_iters=20\\\\markovian_proj_iters=10000\\\\inner_ipmf_mark_proj_iters=5000\\\\ema_start_ipmf=False\\\\plan=ind\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_transport_cost\u001b[39m(x_samples, y_samples):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(x_samples, y_samples)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(exp_path, save_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpics\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './saved_info/dd_gan/cifar10/ddgan_colored_mnist/26:10:24_17:29:18eps=1\\\\T=4\\\\mini_batch_OT=False\\\\D_opt_steps=2\\\\ema_decay=0.99\\\\ipmf_iters=20\\\\markovian_proj_iters=10000\\\\inner_ipmf_mark_proj_iters=5000\\\\ema_start_ipmf=False\\\\plan=ind\\\\'"
     ]
    }
   ],
   "source": [
    "\n",
    "def log_images(x, x_t_1, fake_samples, x_0_pred_list, sample_traj, postfix='fw'):\n",
    "    # from x_t_1 to x\n",
    "    \n",
    "    sample_img_path = os.path.join(exp_path, save_dir, 'pics', f'sample_discrete_M_{postfix}.png')\n",
    "    #print(\"Sizes\", x.shape, x_t_1.shape, fake_samples.shape)\n",
    "    torchvision.utils.save_image(torch.cat([x[:20], x_t_1[:20], fake_samples[:20]], dim=2),\n",
    "                                 sample_img_path, normalize=True, nrow=20)\n",
    "    \n",
    "    sample_traj_path = os.path.join(exp_path, save_dir, 'pics', f'sample_traj_discrete_M_{postfix}.png')\n",
    "\n",
    "    torchvision.utils.save_image(torch.cat(sample_traj, dim=3)[:12],\n",
    "                                 sample_traj_path, normalize=True, nrow=1)\n",
    "    \n",
    "    sample_x_0_pred_path = os.path.join(exp_path, save_dir, 'pics', f'sample_x_0_pred_discrete_M_{postfix}.png')\n",
    "    \n",
    "    torchvision.utils.save_image(torch.cat([x_t_1] + x_0_pred_list +  [x], dim=3)[:12],\n",
    "                                 sample_x_0_pred_path, normalize=True, nrow=1)\n",
    "\n",
    "    sample_input_path = os.path.join(exp_path, save_dir, 'pics', f'input_{postfix}.png')\n",
    "    torchvision.utils.save_image(x_t_1[:16:4], sample_input_path, normalize=True, nrow=1)\n",
    "\n",
    "    samples_path = os.path.join(exp_path, save_dir, 'pics', f'samples_{postfix}.png')\n",
    "    torchvision.utils.save_image(fake_samples[:16], samples_path, normalize=True, nrow=4)\n",
    "    \n",
    "    if wandb.run:\n",
    "        wandb.log({f\"Sample_{postfix}\": wandb.Image(sample_img_path)})\n",
    "        wandb.log({f\"Sample_traj_{postfix}\": wandb.Image(sample_traj_path)})\n",
    "        wandb.log({f\"Sample_x0_pred_{postfix}\": wandb.Image(sample_x_0_pred_path)})\n",
    "        wandb.log({f\"Input {postfix}\": wandb.Image(sample_input_path)})\n",
    "        wandb.log({f\"Samples {postfix}\": wandb.Image(samples_path)})\n",
    "\n",
    "    \n",
    "def calculate_transport_cost(x_samples, y_samples):\n",
    "    return F.mse_loss(x_samples, y_samples)\n",
    "\n",
    "os.makedirs(os.path.join(exp_path, save_dir))\n",
    "\n",
    "os.makedirs(os.path.join(exp_path, save_dir, 'pics'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fa0e2-7f3e-444e-9880-ee92c8e45941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "647c74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def markovian_projection(max_iter, condsampler, netG_proj, netD_proj,\n",
    "                         opt_G_proj, opt_D_proj,\n",
    "                         sch_G_proj, sch_D_proj, ema_g, D_opt_steps=5, fw_or_bw='fw'):\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        if prior:\n",
    "            condsampler_gt = condsampler\n",
    "        else:\n",
    "            if fw_or_bw == 'fw':\n",
    "                condsampler_gt = CondLoaderSampler(data_loader)\n",
    "            else:\n",
    "                condsampler_gt = CondLoaderSampler(data_loader, reverse=True)\n",
    "        \n",
    "        if rank == 0 and iteration % 1000 == 0:\n",
    "            \n",
    "            x, y = condsampler_gt.sample(args.batch_size)\n",
    "            x, x_t_1 = x.to(device), y.to(device)\n",
    "            \n",
    "            \n",
    "            fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_proj, args.num_timesteps, x_t_1, T, args, return_trajectory=True)\n",
    "            # log to wandb\n",
    "            \n",
    "            log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix=fw_or_bw)\n",
    "            \n",
    "            for i in range(args.num_timesteps+1):\n",
    "                torchvision.utils.save_image(trajectory[i], os.path.join(exp_path, f\"gen_x_{args.num_timesteps-i}_M_{fw_or_bw}_{iteration}.png\"), normalize=True)\n",
    "\n",
    "            trajectory = q_sample_supervised_trajectory(pos_coeff, x, x_t_1)\n",
    "            for i in range(args.num_timesteps+1):\n",
    "                torchvision.utils.save_image(trajectory[i], os.path.join(exp_path, f\"x_{args.num_timesteps-i}_M_{fw_or_bw}_{iteration}.png.png\"), normalize=True)\n",
    "            \n",
    "            repeated_samples = torch.cat([pic.unsqueeze(0).repeat([4, 1, 1, 1]) for pic in x_t_1[:10]], dim=0)\n",
    "            \n",
    "            fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_proj,\n",
    "                                                                       args.num_timesteps, repeated_samples,\n",
    "                                                                       T, args, return_trajectory=True)\n",
    "            # log to wandb\n",
    "            \n",
    "            log_images(x[:repeated_samples.shape[0]], repeated_samples, fake_sample, x_0_pred_list, trajectory, postfix=fw_or_bw + '_repeated')\n",
    "        \n",
    "        \n",
    "        if rank == 0 and iteration % 1000 == 0:\n",
    "\n",
    "            with ema_g.average_parameters():\n",
    "\n",
    "                x, y = condsampler_gt.sample(args.batch_size)\n",
    "\n",
    "                x, x_t_1 = x.to(device), y.to(device)\n",
    "                \n",
    "                fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_proj, args.num_timesteps, x_t_1, T, args, return_trajectory=True)\n",
    "                # log to wandb\n",
    "                \n",
    "                log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix=fw_or_bw + '_ema')\n",
    "                \n",
    "                for i in range(args.num_timesteps+1):\n",
    "                    torchvision.utils.save_image(trajectory[i], os.path.join(exp_path, f\"gen_x_{args.num_timesteps-i}_M_{fw_or_bw}_{iteration}_ema.png\"), normalize=True)\n",
    "\n",
    "                trajectory = q_sample_supervised_trajectory(pos_coeff, x, x_t_1)\n",
    "                for i in range(args.num_timesteps+1):\n",
    "                    torchvision.utils.save_image(trajectory[i], os.path.join(exp_path, f\"x_{args.num_timesteps-i}_M_{fw_or_bw}_{iteration}_ema.png\"), normalize=True)\n",
    "                \n",
    "                repeated_samples = torch.cat([pic.unsqueeze(0).repeat([4, 1, 1, 1]) for pic in x_t_1[:10]], dim=0)\n",
    "                \n",
    "                fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_proj,\n",
    "                                                                        args.num_timesteps, repeated_samples,\n",
    "                                                                        T, args, return_trajectory=True)\n",
    "                # log to wandb\n",
    "                \n",
    "                log_images(x[:repeated_samples.shape[0]], repeated_samples, fake_sample, x_0_pred_list, trajectory, postfix=fw_or_bw + '_repeated' + '_ema')\n",
    "                \n",
    "        x, y = condsampler.sample(args.batch_size)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        #-----Discriminator Opt Step-----\n",
    "        \n",
    "        # Get D ready for optimization\n",
    "        for p in netD_proj.parameters():  \n",
    "            p.requires_grad = True  \n",
    "        \n",
    "        netD_proj.zero_grad()\n",
    "\n",
    "        #sample from p(x_0)\n",
    "        real_data = x.to(device, non_blocking=True)\n",
    "        input_real_data = y.to(device, non_blocking=True)\n",
    "\n",
    "        if args.posterior == \"ddpm\":\n",
    "            t = torch.randint(0, args.num_timesteps, (1,), device=device).repeat(real_data.size(0))\n",
    "            x_t, x_tp1 = q_sample_supervised_pairs(pos_coeff, real_data, t, input_real_data)\n",
    "        elif args.posterior == \"brownian_bridge\":\n",
    "            t = torch.randint(0, args.num_timesteps, (real_data.size(0),), device=device)\n",
    "            x_t, x_tp1 = q_sample_supervised_pairs_brownian(pos_coeff, real_data, t, input_real_data)\n",
    "\n",
    "        x_t.requires_grad = True\n",
    "\n",
    "        # train with real\n",
    "        D_real = netD_proj(x_t, t, x_tp1.detach()).view(-1)\n",
    "\n",
    "        errD_real = F.softplus(-D_real)\n",
    "        errD_real = errD_real.mean()\n",
    "\n",
    "        errD_real.backward(retain_graph=True)\n",
    "\n",
    "        if args.lazy_reg is None:\n",
    "            grad_real = torch.autograd.grad(\n",
    "                        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "                        )[0]\n",
    "            grad_penalty = (\n",
    "                            grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "                            ).mean()\n",
    "\n",
    "\n",
    "            grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "            grad_penalty.backward()\n",
    "        else:\n",
    "            if iteration % args.lazy_reg == 0:\n",
    "                grad_real = torch.autograd.grad(\n",
    "                        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "                        )[0]\n",
    "                grad_penalty = (\n",
    "                            grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "                            ).mean()\n",
    "\n",
    "\n",
    "                grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "                grad_penalty.backward()\n",
    "        \n",
    "        # train with fake\n",
    "        latent_z = torch.randn(batch_size, nz, device=device)\n",
    "\n",
    "        x_0_predict = netG_proj(x_tp1.detach(), t, latent_z)\n",
    "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "        \n",
    "        output = netD_proj(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "        \n",
    "        errD_fake = F.softplus(output)\n",
    "        errD_fake = errD_fake.mean()\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        opt_D_proj.step()\n",
    "        \n",
    "        \n",
    "        #-----Generator Opt Step-----\n",
    "        \n",
    "        if iteration % D_opt_steps == 0:\n",
    "        \n",
    "            # Get G ready for optimization\n",
    "            for p in netD_proj.parameters():\n",
    "                p.requires_grad = False\n",
    "            netG_proj.zero_grad()\n",
    "\n",
    "            if args.posterior == \"brownian_bridge\":\n",
    "                t = torch.randint(0, args.num_timesteps, (real_data.size(0),), device=device)\n",
    "                x_t, x_tp1 = q_sample_supervised_pairs_brownian(pos_coeff, real_data, t, input_real_data)\n",
    "            else:\n",
    "                raise ValueError('ONLY Brownian Bridge posterior')\n",
    "\n",
    "\n",
    "            latent_z = torch.randn(batch_size, nz,device=device)\n",
    "\n",
    "\n",
    "            x_0_predict = netG_proj(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD_proj(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "\n",
    "\n",
    "            errG = F.softplus(-output)\n",
    "            errG = errG.mean()\n",
    "\n",
    "\n",
    "            errG.backward()\n",
    "            opt_G_proj.step()\n",
    "            ema_g.update()\n",
    "        \n",
    "            if wandb.run:\n",
    "                wandb.log({'LossG': errG.item(), 'LossD': errD.item()})\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            if rank == 0:\n",
    "                print('Markovain proj {}: Iter {}, G Loss: {}, D Loss: {}'.format(fw_or_bw, iteration, errG.item(), errD.item()))\n",
    "\n",
    "#         # SCH iteration step\n",
    "#         if not args.no_lr_decay and iteration % 1000 == 0:\n",
    "\n",
    "#             sch_G_proj.step()\n",
    "#             sch_D_proj.step()\n",
    "\n",
    "    if rank == 0:\n",
    "        \n",
    "        if args.save_content:\n",
    "            if epoch % args.save_content_every == 0:\n",
    "                print('Saving content.')\n",
    "                content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                           'netG_dict': netG_proj.state_dict(), 'optimizerG': opt_G_proj.state_dict(),\n",
    "                           'netD_dict': netD_proj.state_dict(),\n",
    "                           'optimizerD': opt_D_proj.state_dict()}\n",
    "                \n",
    "                torch.save(content, os.path.join(exp_path, save_dir, f'content_{fw_or_bw}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245c1a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrazvor\u001b[0m (\u001b[33mrazvors_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/razvor/Documents/DS/Skoltech/GenAI/ipmf_submit/ASBM/cMNIST/wandb/run-20241026_173018-yhug57i7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/razvors_team/BM_GAN_CIFAR/runs/yhug57i7' target=\"_blank\">BMGAN_Cifar_downsample</a></strong> to <a href='https://wandb.ai/razvors_team/BM_GAN_CIFAR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/razvors_team/BM_GAN_CIFAR' target=\"_blank\">https://wandb.ai/razvors_team/BM_GAN_CIFAR</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/razvors_team/BM_GAN_CIFAR/runs/yhug57i7' target=\"_blank\">https://wandb.ai/razvors_team/BM_GAN_CIFAR/runs/yhug57i7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/razvors_team/BM_GAN_CIFAR/runs/yhug57i7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f75cade0e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"d819ea0d92a856b5544d1aa919f503250223447c\" # Change to your W&B profile if you need it\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "wandb.init(project=\"BM_GAN_CIFAR\", name=exp_name, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f86c7d4d-3da5-457e-be3f-0c1362b0482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coloring_seed = 42\n",
    "\n",
    "\"\"\"colored_mnist_2 = load_paired_colored_mnist_one_side(target_number=2, train=False,\n",
    "                                            seed=coloring_seed, dataset_size=10000)\n",
    "\n",
    "colored_mnist_3 = load_paired_colored_mnist_one_side(target_number=3, train=False,\n",
    "                                            seed=coloring_seed, dataset_size=10000)\n",
    "\n",
    "\n",
    "\n",
    "colored_mnist_2_loader = DataLoader(colored_mnist_2, batch_size=256)\n",
    "colored_mnist_3_loader = DataLoader(colored_mnist_3, batch_size=256)\n",
    "\n",
    "true_dataloader_bw = colored_mnist_3_loader\n",
    "\n",
    "model_input_dataloader_bw = colored_mnist_2_loader\n",
    "\n",
    "true_dataloader_fw = colored_mnist_2_loader\n",
    "\n",
    "model_input_dataloader_fw = colored_mnist_3_loader\"\"\"\n",
    "\n",
    "cifar_high = load_paired_cifar(dataset_, dataset_small_, backwards=False, right_zero=True)\n",
    "cifar_low = load_paired_cifar(dataset_, dataset_small_, backwards=True, right_zero=True)\n",
    "cifar_high_loader = DataLoader(cifar_high, batch_size=256)\n",
    "cifar_low_loader = DataLoader(cifar_low, batch_size=256)\n",
    "\n",
    "true_dataloader_bw = cifar_low_loader\n",
    "model_input_dataloader_bw = cifar_high_loader\n",
    "\n",
    "true_dataloader_fw = cifar_high_loader\n",
    "model_input_dataloader_fw = cifar_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c28aa51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCSNpp, nz = 100, z_emb_dim = 256, num_channels_dae = 128, ch_mult = [1, 2, 2, 2], n_mlp = 4, num_res_blocks = 2, attn_resolutions = (16,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "netG_fw = NCSNpp(args).to(device)\n",
    "\n",
    "netD_fw = Discriminator_small(nc = 2*args.num_channels, ngf = args.ngf,\n",
    "                           t_emb_dim = args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2)).to(device)\n",
    "\n",
    "optimizerG_fw = optim.Adam(netG_fw.parameters(),\n",
    "                           lr=args.lr_g, betas = (args.beta1, args.beta2))\n",
    "optimizerD_fw = optim.Adam(netD_fw.parameters(),\n",
    "                           lr=args.lr_d, betas = (args.beta1, args.beta2))\n",
    "\n",
    "schedulerG_fw = None\n",
    "schedulerD_fw = None\n",
    "\n",
    "# schedulerG_fw = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerG_fw, 100, eta_min=1e-5)\n",
    "# schedulerD_fw = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerD_fw, 100, eta_min=1e-5)\n",
    "\n",
    "ema_g_fw = ExponentialMovingAverage(netG_fw.parameters(), decay=args.ema_decay)\n",
    "ema_g_fw.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "322dfe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCSNpp, nz = 100, z_emb_dim = 256, num_channels_dae = 128, ch_mult = [1, 2, 2, 2], n_mlp = 4, num_res_blocks = 2, attn_resolutions = (16,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "netG_bw = NCSNpp(args).to(device)\n",
    "\n",
    "netD_bw = Discriminator_small(nc = 2*args.num_channels, ngf = args.ngf,\n",
    "                           t_emb_dim = args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2)).to(device)\n",
    "\n",
    "optimizerG_bw = optim.Adam(netG_bw.parameters(),\n",
    "                           lr=args.lr_g, betas = (args.beta1, args.beta2))\n",
    "optimizerD_bw = optim.Adam(netD_bw.parameters(),\n",
    "                           lr=args.lr_d, betas = (args.beta1, args.beta2))\n",
    "\n",
    "schedulerG_bw = None\n",
    "schedulerD_bw = None\n",
    "\n",
    "# schedulerG_bw = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerG_bw, 100, eta_min=1e-5)\n",
    "# schedulerD_bw = torch.optim.lr_scheduler.CosineAnnealingLR(optimizerD_bw, 100, eta_min=1e-5)\n",
    "\n",
    "ema_g_bw = ExponentialMovingAverage(netG_bw.parameters(), decay=args.ema_decay)\n",
    "ema_g_bw.to(device)\n",
    "\n",
    "#     optimizerG_bw = EMA(optimizerG_fw, ema_decay=args.ema_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd307cb0",
   "metadata": {},
   "source": [
    "## ipmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f77380",
   "metadata": {},
   "source": [
    "### First forward iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9a12a-77b6-4419-924d-3c9fcefc65c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d194fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj fw: Iter 0, G Loss: 1.2662832736968994, D Loss: 1.3862919807434082\n",
      "Markovain proj fw: Iter 100, G Loss: 0.6886044144630432, D Loss: 1.3662716150283813\n",
      "Markovain proj fw: Iter 200, G Loss: 0.6840886473655701, D Loss: 1.3454103469848633\n",
      "Markovain proj fw: Iter 300, G Loss: 0.5934921503067017, D Loss: 1.263070821762085\n",
      "Markovain proj fw: Iter 400, G Loss: 0.7828807830810547, D Loss: 1.4596991539001465\n",
      "Markovain proj fw: Iter 500, G Loss: 0.030763136222958565, D Loss: 1.2952592372894287\n",
      "Markovain proj fw: Iter 600, G Loss: 3.3505022525787354, D Loss: 0.9564976096153259\n",
      "Markovain proj fw: Iter 700, G Loss: 1.0044305324554443, D Loss: 1.129852294921875\n",
      "Markovain proj fw: Iter 800, G Loss: 2.0430541038513184, D Loss: 1.0183238983154297\n",
      "Markovain proj fw: Iter 900, G Loss: 3.84625244140625, D Loss: 1.1846885681152344\n",
      "Markovain proj fw: Iter 1000, G Loss: 1.4573864936828613, D Loss: 2.131495952606201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.273091, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj fw: Iter 1100, G Loss: 0.34288644790649414, D Loss: 1.7889246940612793\n",
      "Markovain proj fw: Iter 1200, G Loss: 2.588815450668335, D Loss: 2.3500661849975586\n",
      "Markovain proj fw: Iter 1300, G Loss: 2.496061086654663, D Loss: 1.184662103652954\n",
      "Markovain proj fw: Iter 1400, G Loss: 1.4631669521331787, D Loss: 0.7916666865348816\n",
      "Markovain proj fw: Iter 1500, G Loss: 1.8390493392944336, D Loss: 1.5196154117584229\n",
      "Markovain proj fw: Iter 1600, G Loss: 0.654207706451416, D Loss: 1.2521464824676514\n",
      "Markovain proj fw: Iter 1700, G Loss: 2.6903843879699707, D Loss: 0.9656921625137329\n",
      "Markovain proj fw: Iter 1800, G Loss: 2.443289279937744, D Loss: 0.8950133323669434\n",
      "Markovain proj fw: Iter 1900, G Loss: 3.924802780151367, D Loss: 1.037309169769287\n",
      "Markovain proj fw: Iter 2000, G Loss: 1.760810136795044, D Loss: 1.112339735031128\n",
      "Markovain proj fw: Iter 2100, G Loss: 0.38881897926330566, D Loss: 1.3114495277404785\n",
      "Markovain proj fw: Iter 2200, G Loss: 1.0282578468322754, D Loss: 0.9958625435829163\n",
      "Markovain proj fw: Iter 2300, G Loss: 0.22195595502853394, D Loss: 1.2995750904083252\n",
      "Markovain proj fw: Iter 2400, G Loss: 0.5730710029602051, D Loss: 1.1077637672424316\n",
      "Markovain proj fw: Iter 2500, G Loss: 1.4892908334732056, D Loss: 1.578076720237732\n",
      "Markovain proj fw: Iter 2600, G Loss: 1.8142280578613281, D Loss: 1.0854724645614624\n",
      "Markovain proj fw: Iter 2700, G Loss: 2.1362805366516113, D Loss: 1.20675790309906\n",
      "Markovain proj fw: Iter 2800, G Loss: 1.2200931310653687, D Loss: 1.0924900770187378\n",
      "Markovain proj fw: Iter 2900, G Loss: 1.5104405879974365, D Loss: 1.1303110122680664\n",
      "Markovain proj fw: Iter 3000, G Loss: 2.2059977054595947, D Loss: 1.4340472221374512\n",
      "Markovain proj fw: Iter 3100, G Loss: 2.394493579864502, D Loss: 1.0360324382781982\n",
      "Markovain proj fw: Iter 3200, G Loss: 3.8271560668945312, D Loss: 1.116901159286499\n",
      "Markovain proj fw: Iter 3300, G Loss: 8.867413520812988, D Loss: 0.8038167357444763\n",
      "Markovain proj fw: Iter 3400, G Loss: 0.4665498733520508, D Loss: 2.5339980125427246\n",
      "Markovain proj fw: Iter 3500, G Loss: 1.14005708694458, D Loss: 1.8053382635116577\n",
      "Markovain proj fw: Iter 3600, G Loss: 1.0815098285675049, D Loss: 1.3316566944122314\n",
      "Markovain proj fw: Iter 3700, G Loss: 2.543996810913086, D Loss: 1.3245275020599365\n",
      "Markovain proj fw: Iter 3800, G Loss: 2.27292537689209, D Loss: 1.122809886932373\n",
      "Markovain proj fw: Iter 3900, G Loss: 1.9840011596679688, D Loss: 0.9466135501861572\n",
      "Markovain proj fw: Iter 4000, G Loss: 1.60853910446167, D Loss: 1.1301283836364746\n",
      "Markovain proj fw: Iter 4100, G Loss: 8.051769256591797, D Loss: 0.9252007007598877\n",
      "Markovain proj fw: Iter 4200, G Loss: 0.9782127141952515, D Loss: 1.4258723258972168\n",
      "Markovain proj fw: Iter 4300, G Loss: 0.7777113318443298, D Loss: 1.1245911121368408\n",
      "Markovain proj fw: Iter 4400, G Loss: 1.2434759140014648, D Loss: 1.1726672649383545\n",
      "Markovain proj fw: Iter 4500, G Loss: 0.6044630408287048, D Loss: 1.8113641738891602\n",
      "Markovain proj fw: Iter 4600, G Loss: 1.5314726829528809, D Loss: 1.152801275253296\n",
      "Markovain proj fw: Iter 4700, G Loss: 1.0215613842010498, D Loss: 1.1191588640213013\n",
      "Markovain proj fw: Iter 4800, G Loss: 0.8602725267410278, D Loss: 1.4744207859039307\n",
      "Markovain proj fw: Iter 4900, G Loss: 2.641572952270508, D Loss: 1.0873918533325195\n",
      "Markovain proj fw: Iter 5000, G Loss: 1.143387794494629, D Loss: 1.2215394973754883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.263573, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj fw: Iter 5100, G Loss: 1.828729510307312, D Loss: 1.081748366355896\n",
      "Markovain proj fw: Iter 5200, G Loss: 1.9134801626205444, D Loss: 1.2330480813980103\n",
      "Markovain proj fw: Iter 5300, G Loss: 1.6004056930541992, D Loss: 1.2310948371887207\n",
      "Markovain proj fw: Iter 5400, G Loss: 0.4820529818534851, D Loss: 1.311396598815918\n",
      "Markovain proj fw: Iter 5500, G Loss: 1.4785610437393188, D Loss: 1.4339919090270996\n",
      "Markovain proj fw: Iter 5600, G Loss: 3.760798692703247, D Loss: 1.2865766286849976\n",
      "Markovain proj fw: Iter 5700, G Loss: 0.6290011405944824, D Loss: 1.3104192018508911\n",
      "Markovain proj fw: Iter 5800, G Loss: 0.8601955771446228, D Loss: 1.2070295810699463\n",
      "Markovain proj fw: Iter 5900, G Loss: 2.84024715423584, D Loss: 1.0888649225234985\n",
      "Markovain proj fw: Iter 6000, G Loss: 1.1679866313934326, D Loss: 1.0152928829193115\n",
      "Markovain proj fw: Iter 6100, G Loss: 1.4585518836975098, D Loss: 1.368452787399292\n",
      "Markovain proj fw: Iter 6200, G Loss: 1.263163447380066, D Loss: 1.0826588869094849\n",
      "Markovain proj fw: Iter 6300, G Loss: 0.7532745599746704, D Loss: 1.3237583637237549\n",
      "Markovain proj fw: Iter 6400, G Loss: 3.289921283721924, D Loss: 0.9553931355476379\n",
      "Markovain proj fw: Iter 6500, G Loss: 0.6694808006286621, D Loss: 1.3011717796325684\n",
      "Markovain proj fw: Iter 6600, G Loss: 1.2532806396484375, D Loss: 1.380298376083374\n",
      "Markovain proj fw: Iter 6700, G Loss: 0.3071433901786804, D Loss: 1.3026885986328125\n",
      "Markovain proj fw: Iter 6800, G Loss: 0.7867097854614258, D Loss: 1.1136200428009033\n",
      "Markovain proj fw: Iter 6900, G Loss: 0.9139305353164673, D Loss: 1.233756184577942\n",
      "Markovain proj fw: Iter 7000, G Loss: 4.065993309020996, D Loss: 0.9426194429397583\n",
      "Markovain proj fw: Iter 7100, G Loss: 0.6321365833282471, D Loss: 1.2776470184326172\n",
      "Markovain proj fw: Iter 7200, G Loss: 3.462498664855957, D Loss: 1.1582176685333252\n",
      "Markovain proj fw: Iter 7300, G Loss: 1.579098105430603, D Loss: 1.2940059900283813\n",
      "Markovain proj fw: Iter 7400, G Loss: 1.2011067867279053, D Loss: 1.0572352409362793\n",
      "Markovain proj fw: Iter 7500, G Loss: 2.9078471660614014, D Loss: 0.9339287877082825\n",
      "Markovain proj fw: Iter 7600, G Loss: 0.7382813096046448, D Loss: 1.5300581455230713\n",
      "Markovain proj fw: Iter 7700, G Loss: 1.5439772605895996, D Loss: 1.2771263122558594\n",
      "Markovain proj fw: Iter 7800, G Loss: 4.0825653076171875, D Loss: 1.32185697555542\n",
      "Markovain proj fw: Iter 7900, G Loss: 2.539666175842285, D Loss: 1.227132797241211\n",
      "Markovain proj fw: Iter 8000, G Loss: 1.7348400354385376, D Loss: 1.1824464797973633\n",
      "Markovain proj fw: Iter 8100, G Loss: 0.7759830951690674, D Loss: 1.2719866037368774\n",
      "Markovain proj fw: Iter 8200, G Loss: 1.018223524093628, D Loss: 0.9867416620254517\n",
      "Markovain proj fw: Iter 8300, G Loss: 0.7434085607528687, D Loss: 1.1160234212875366\n",
      "Markovain proj fw: Iter 8400, G Loss: 0.6009823083877563, D Loss: 1.4050158262252808\n",
      "Markovain proj fw: Iter 8500, G Loss: 0.5807890892028809, D Loss: 1.749504566192627\n",
      "Markovain proj fw: Iter 8600, G Loss: 2.4391918182373047, D Loss: 0.9623515605926514\n",
      "Markovain proj fw: Iter 8700, G Loss: 2.1002936363220215, D Loss: 1.115851640701294\n",
      "Markovain proj fw: Iter 8800, G Loss: 0.7459276914596558, D Loss: 1.214767575263977\n",
      "Markovain proj fw: Iter 8900, G Loss: 1.721632957458496, D Loss: 1.240908145904541\n",
      "Markovain proj fw: Iter 9000, G Loss: 1.6133511066436768, D Loss: 1.0253708362579346\n",
      "Markovain proj fw: Iter 9100, G Loss: 0.5676621198654175, D Loss: 1.1739449501037598\n",
      "Markovain proj fw: Iter 9200, G Loss: 0.6832364797592163, D Loss: 1.3286325931549072\n",
      "Markovain proj fw: Iter 9300, G Loss: 0.7304398417472839, D Loss: 1.0814762115478516\n",
      "Markovain proj fw: Iter 9400, G Loss: 0.3864631652832031, D Loss: 2.345109462738037\n",
      "Markovain proj fw: Iter 9500, G Loss: 1.1956642866134644, D Loss: 1.089288353919983\n",
      "Markovain proj fw: Iter 9600, G Loss: 0.5883344411849976, D Loss: 1.3979060649871826\n",
      "Markovain proj fw: Iter 9700, G Loss: 1.1661361455917358, D Loss: 1.084404468536377\n",
      "Markovain proj fw: Iter 9800, G Loss: 1.5345535278320312, D Loss: 0.9636865854263306\n",
      "Markovain proj fw: Iter 9900, G Loss: 1.2721589803695679, D Loss: 1.107501745223999\n",
      "Saving content.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# FID\u001b[39;00m\n\u001b[1;32m     25\u001b[0m sample_fn_fw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y: sample_from_model(pos_coeff, netG_fw,\n\u001b[1;32m     26\u001b[0m                                             args\u001b[38;5;241m.\u001b[39mnum_timesteps, y, T,\n\u001b[1;32m     27\u001b[0m                                             args, return_trajectory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m fid, ot_cost \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_fid_and_ot_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_dataloader_fw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_dataloader_fw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_fn_fw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ema_g_fw\u001b[38;5;241m.\u001b[39maverage_parameters():\n\u001b[1;32m     33\u001b[0m     sample_fn_fw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y: sample_from_model(pos_coeff, netG_fw,\n\u001b[1;32m     34\u001b[0m                                                 args\u001b[38;5;241m.\u001b[39mnum_timesteps, y, T,\n\u001b[1;32m     35\u001b[0m                                                 args, return_trajectory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mcompute_fid_and_ot_cost\u001b[0;34m(true_dataloader, model_input_dataloader, sample_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(model_input_dataloader):\n\u001b[1;32m     22\u001b[0m     y \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m     fake_sample \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     fid\u001b[38;5;241m.\u001b[39mupdate(to_uint8_tensor(fake_sample\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), real\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m     ot_cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(fake_sample\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;241m*\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     22\u001b[0m transport_cost_ind \u001b[38;5;241m=\u001b[39m calculate_transport_cost(x_t_1, x)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# FID\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m sample_fn_fw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y: \u001b[43msample_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_coeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetG_fw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_trajectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m fid, ot_cost \u001b[38;5;241m=\u001b[39m compute_fid_and_ot_cost(true_dataloader_fw, model_input_dataloader_fw, sample_fn_fw)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ema_g_fw\u001b[38;5;241m.\u001b[39maverage_parameters():\n",
      "Cell \u001b[0;32mIn[7], line 255\u001b[0m, in \u001b[0;36msample_from_model\u001b[0;34m(coefficients, generator, n_time, x_init, T, opt, return_trajectory)\u001b[0m\n\u001b[1;32m    253\u001b[0m t_time \u001b[38;5;241m=\u001b[39m t\n\u001b[1;32m    254\u001b[0m latent_z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), opt\u001b[38;5;241m.\u001b[39mnz, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 255\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m x_new \u001b[38;5;241m=\u001b[39m sample_posterior(coefficients, x_0, x, t)\n\u001b[1;32m    257\u001b[0m x \u001b[38;5;241m=\u001b[39m x_new\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/optt11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/razvor/Documents/DS/Skoltech/GenAI/ipmf_submit/ASBM/cMNIST/score_sde/models/ncsnpp_generator_adagn.py:350\u001b[0m, in \u001b[0;36mNCSNpp.forward\u001b[0;34m(self, x, time_cond, z)\u001b[0m\n\u001b[1;32m    347\u001b[0m   m_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogressive_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 350\u001b[0m   input_pyramid \u001b[38;5;241m=\u001b[39m \u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pyramid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m   m_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    352\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_rescale:\n",
      "File \u001b[0;32m~/miniconda3/envs/optt11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/razvor/Documents/DS/Skoltech/GenAI/ipmf_submit/ASBM/cMNIST/score_sde/models/layerspp.py:183\u001b[0m, in \u001b[0;36mDownsample.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 183\u001b[0m   B, C, H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfir:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_conv:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "prior = True\n",
    "condsampler_fw = CondLoaderSampler(prior_data_loader, args.plan)\n",
    "\n",
    "# if mini_batch_OT:\n",
    "#     condsampler_fw = OTSampler(condsampler_fw)\n",
    "\n",
    "markovian_projection(markovian_proj_iters, condsampler_fw, netG_fw, netD_fw,\n",
    "                         optimizerG_fw, optimizerD_fw,\n",
    "                         schedulerG_fw, schedulerD_fw, ema_g_fw, D_opt_steps=D_opt_steps, fw_or_bw='fw')\n",
    "\n",
    "x, y = condsampler_fw.sample(args.batch_size)\n",
    "\n",
    "x, x_t_1 = x.to(device), y.to(device)\n",
    "\n",
    "fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_fw,\n",
    "                                            args.num_timesteps, x_t_1, T,\n",
    "                                            args, return_trajectory=True)\n",
    "\n",
    "log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix='fw_after_M')\n",
    "\n",
    "transport_cost_model = calculate_transport_cost(x_t_1, fake_sample)\n",
    "transport_cost_ind = calculate_transport_cost(x_t_1, x)\n",
    "\n",
    "# FID\n",
    "sample_fn_fw = lambda y: sample_from_model(pos_coeff, netG_fw,\n",
    "                                            args.num_timesteps, y, T,\n",
    "                                            args, return_trajectory=True)[0]\n",
    "\n",
    "fid, ot_cost = compute_fid_and_ot_cost(true_dataloader_fw, model_input_dataloader_fw, sample_fn_fw)\n",
    "\n",
    "with ema_g_fw.average_parameters():\n",
    "    \n",
    "    sample_fn_fw = lambda y: sample_from_model(pos_coeff, netG_fw,\n",
    "                                                args.num_timesteps, y, T,\n",
    "                                                args, return_trajectory=True)[0]\n",
    "    \n",
    "    fid_ema, ot_cost_ema = compute_fid_and_ot_cost(true_dataloader_fw, model_input_dataloader_fw, sample_fn_fw)\n",
    "\n",
    "if wandb.run:\n",
    "    wandb.log({'T_cost_fw': transport_cost_model, 'T_cost_ind': transport_cost_ind,\n",
    "               'fid_fw': fid, 'fid_fw_ema': fid_ema,\n",
    "               'ot_cost_fw': ot_cost, 'ot_cost_fw_ema': ot_cost_ema})\n",
    "\n",
    "torch.save(netG_fw.state_dict(), os.path.join(exp_path, save_dir, f'netG_fw_0.pth'))\n",
    "\n",
    "with ema_g_fw.average_parameters():\n",
    "    torch.save(netG_fw.state_dict(), os.path.join(exp_path, save_dir, f'netG_fw_0_ema.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1afc9-2eac-451c-aed2-57f681ee9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ca070",
   "metadata": {},
   "source": [
    "### First backward iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf237ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj bw: Iter 0, G Loss: 2.3635683059692383, D Loss: 1.386294960975647\n",
      "Markovain proj bw: Iter 100, G Loss: 0.06388796865940094, D Loss: 8.358480453491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.267115, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj bw: Iter 200, G Loss: 0.4097245931625366, D Loss: 1.9333475828170776\n",
      "Markovain proj bw: Iter 300, G Loss: 0.5921955108642578, D Loss: 1.3164992332458496\n",
      "Markovain proj bw: Iter 400, G Loss: 1.9560210704803467, D Loss: 1.226304531097412\n",
      "Markovain proj bw: Iter 500, G Loss: 0.5036044120788574, D Loss: 2.6830246448516846\n",
      "Markovain proj bw: Iter 600, G Loss: 2.831754207611084, D Loss: 1.022769808769226\n",
      "Markovain proj bw: Iter 700, G Loss: 0.8861484527587891, D Loss: 1.5655523538589478\n",
      "Markovain proj bw: Iter 800, G Loss: 0.5505772233009338, D Loss: 1.0583587884902954\n",
      "Markovain proj bw: Iter 900, G Loss: 1.3480744361877441, D Loss: 1.291761875152588\n",
      "Markovain proj bw: Iter 1000, G Loss: 17.853199005126953, D Loss: 0.8223460912704468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:21.271616, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markovain proj bw: Iter 1100, G Loss: 2.1338753700256348, D Loss: 1.0437047481536865\n",
      "Markovain proj bw: Iter 1200, G Loss: 1.4832640886306763, D Loss: 1.251095175743103\n",
      "Markovain proj bw: Iter 1300, G Loss: 1.9151451587677002, D Loss: 1.4016226530075073\n",
      "Markovain proj bw: Iter 1400, G Loss: 4.810345649719238, D Loss: 1.077460527420044\n",
      "Markovain proj bw: Iter 1500, G Loss: 3.1378955841064453, D Loss: 1.0946400165557861\n",
      "Markovain proj bw: Iter 1600, G Loss: 0.8946588039398193, D Loss: 1.2076842784881592\n",
      "Markovain proj bw: Iter 1700, G Loss: 0.9291446805000305, D Loss: 0.8743040561676025\n",
      "Markovain proj bw: Iter 1800, G Loss: 5.619075775146484, D Loss: 1.1255749464035034\n",
      "Markovain proj bw: Iter 1900, G Loss: 1.3681889772415161, D Loss: 1.2484428882598877\n",
      "Markovain proj bw: Iter 2000, G Loss: 1.6730186939239502, D Loss: 0.9531487226486206\n",
      "Markovain proj bw: Iter 2100, G Loss: 1.9149870872497559, D Loss: 1.1009302139282227\n",
      "Markovain proj bw: Iter 2200, G Loss: 2.0625972747802734, D Loss: 0.4749751687049866\n",
      "Markovain proj bw: Iter 2300, G Loss: 3.622002124786377, D Loss: 0.9078510403633118\n",
      "Markovain proj bw: Iter 2400, G Loss: 0.9276331067085266, D Loss: 1.1802042722702026\n",
      "Markovain proj bw: Iter 2500, G Loss: 2.1460108757019043, D Loss: 0.9855976104736328\n",
      "Markovain proj bw: Iter 2600, G Loss: 2.47173810005188, D Loss: 0.9826117753982544\n",
      "Markovain proj bw: Iter 2700, G Loss: 1.452695369720459, D Loss: 0.8034323453903198\n",
      "Markovain proj bw: Iter 2800, G Loss: 0.8261765241622925, D Loss: 1.1459282636642456\n",
      "Markovain proj bw: Iter 2900, G Loss: 1.2401572465896606, D Loss: 1.409869909286499\n",
      "Markovain proj bw: Iter 3000, G Loss: 1.3600112199783325, D Loss: 2.9876022338867188\n",
      "Markovain proj bw: Iter 3100, G Loss: 1.2109553813934326, D Loss: 0.7187237739562988\n",
      "Markovain proj bw: Iter 3200, G Loss: 4.400769233703613, D Loss: 0.9098875522613525\n",
      "Markovain proj bw: Iter 3300, G Loss: 2.5010035037994385, D Loss: 0.9279314279556274\n",
      "Markovain proj bw: Iter 3400, G Loss: 2.874332904815674, D Loss: 1.0115916728973389\n",
      "Markovain proj bw: Iter 3500, G Loss: 1.742551565170288, D Loss: 0.8544211387634277\n",
      "Markovain proj bw: Iter 3600, G Loss: 1.5398623943328857, D Loss: 1.1436189413070679\n",
      "Markovain proj bw: Iter 3700, G Loss: 0.4358125329017639, D Loss: 1.220909833908081\n",
      "Markovain proj bw: Iter 3800, G Loss: 2.9836788177490234, D Loss: 1.0459489822387695\n",
      "Markovain proj bw: Iter 3900, G Loss: 1.7280389070510864, D Loss: 1.0206184387207031\n",
      "Markovain proj bw: Iter 4000, G Loss: 1.792396903038025, D Loss: 1.0630629062652588\n",
      "Markovain proj bw: Iter 4100, G Loss: 1.3594672679901123, D Loss: 1.107630968093872\n",
      "Markovain proj bw: Iter 4200, G Loss: 2.449537992477417, D Loss: 0.5256103277206421\n",
      "Markovain proj bw: Iter 4300, G Loss: 2.0102715492248535, D Loss: 0.9173868298530579\n",
      "Markovain proj bw: Iter 4400, G Loss: 0.781176745891571, D Loss: 1.5074574947357178\n",
      "Markovain proj bw: Iter 4500, G Loss: 1.423485517501831, D Loss: 0.9424424767494202\n",
      "Markovain proj bw: Iter 4600, G Loss: 2.3782198429107666, D Loss: 1.1021149158477783\n",
      "Markovain proj bw: Iter 4700, G Loss: 1.4223229885101318, D Loss: 1.379954218864441\n",
      "Markovain proj bw: Iter 4800, G Loss: 1.4020118713378906, D Loss: 1.2606674432754517\n",
      "Markovain proj bw: Iter 4900, G Loss: 4.217399597167969, D Loss: 0.9568049907684326\n",
      "Markovain proj bw: Iter 5000, G Loss: 2.2973060607910156, D Loss: 0.7666254639625549\n",
      "Markovain proj bw: Iter 5100, G Loss: 1.8631494045257568, D Loss: 1.2455759048461914\n",
      "Markovain proj bw: Iter 5200, G Loss: 0.6266937255859375, D Loss: 2.0363168716430664\n",
      "Markovain proj bw: Iter 5300, G Loss: 0.2517566680908203, D Loss: 1.802154779434204\n",
      "Markovain proj bw: Iter 5400, G Loss: 0.5679027438163757, D Loss: 2.2271945476531982\n",
      "Markovain proj bw: Iter 5500, G Loss: 1.2131671905517578, D Loss: 1.2202411890029907\n",
      "Markovain proj bw: Iter 5600, G Loss: 1.4871063232421875, D Loss: 1.0439136028289795\n",
      "Markovain proj bw: Iter 5700, G Loss: 2.395827293395996, D Loss: 0.8995702266693115\n",
      "Markovain proj bw: Iter 5800, G Loss: 4.167654991149902, D Loss: 0.9832990765571594\n",
      "Markovain proj bw: Iter 5900, G Loss: 0.40065935254096985, D Loss: 1.450256586074829\n",
      "Markovain proj bw: Iter 6000, G Loss: 1.1640350818634033, D Loss: 1.045455813407898\n",
      "Markovain proj bw: Iter 6100, G Loss: 3.7758235931396484, D Loss: 1.03385329246521\n",
      "Markovain proj bw: Iter 6200, G Loss: 1.480980634689331, D Loss: 1.2204868793487549\n",
      "Markovain proj bw: Iter 6300, G Loss: 1.408776044845581, D Loss: 1.229300856590271\n",
      "Markovain proj bw: Iter 6400, G Loss: 1.1775661706924438, D Loss: 1.1595911979675293\n",
      "Markovain proj bw: Iter 6500, G Loss: 1.959397554397583, D Loss: 0.9772042036056519\n",
      "Markovain proj bw: Iter 6600, G Loss: 1.3648712635040283, D Loss: 1.1590960025787354\n",
      "Markovain proj bw: Iter 6700, G Loss: 1.256129264831543, D Loss: 1.136392593383789\n",
      "Markovain proj bw: Iter 6800, G Loss: 1.6102347373962402, D Loss: 1.1814563274383545\n",
      "Markovain proj bw: Iter 6900, G Loss: 1.8831377029418945, D Loss: 1.0443917512893677\n",
      "Markovain proj bw: Iter 7000, G Loss: 2.370969295501709, D Loss: 1.2240177392959595\n",
      "Markovain proj bw: Iter 7100, G Loss: 1.4907021522521973, D Loss: 1.2187118530273438\n",
      "Markovain proj bw: Iter 7200, G Loss: 3.10247802734375, D Loss: 0.9745720028877258\n",
      "Markovain proj bw: Iter 7300, G Loss: 1.486292839050293, D Loss: 1.1146217584609985\n",
      "Markovain proj bw: Iter 7400, G Loss: 0.632258951663971, D Loss: 1.2776732444763184\n",
      "Markovain proj bw: Iter 7500, G Loss: 0.814511239528656, D Loss: 0.994373083114624\n",
      "Markovain proj bw: Iter 7600, G Loss: 0.8714463710784912, D Loss: 3.1095731258392334\n",
      "Markovain proj bw: Iter 7700, G Loss: 3.154635190963745, D Loss: 1.0458040237426758\n",
      "Markovain proj bw: Iter 7800, G Loss: 1.5017139911651611, D Loss: 1.2135295867919922\n",
      "Markovain proj bw: Iter 7900, G Loss: 1.302527904510498, D Loss: 1.9009124040603638\n",
      "Markovain proj bw: Iter 8000, G Loss: 1.856589436531067, D Loss: 1.1553318500518799\n",
      "Markovain proj bw: Iter 8100, G Loss: 1.6441261768341064, D Loss: 1.1784286499023438\n",
      "Markovain proj bw: Iter 8200, G Loss: 1.2306472063064575, D Loss: 1.1094574928283691\n",
      "Markovain proj bw: Iter 8300, G Loss: 1.1532822847366333, D Loss: 1.2661348581314087\n",
      "Markovain proj bw: Iter 8400, G Loss: 1.6197710037231445, D Loss: 1.214296579360962\n",
      "Markovain proj bw: Iter 8500, G Loss: 4.965661525726318, D Loss: 0.9718835353851318\n",
      "Markovain proj bw: Iter 8600, G Loss: 1.3698253631591797, D Loss: 1.200426697731018\n",
      "Markovain proj bw: Iter 8700, G Loss: 0.5779313445091248, D Loss: 1.3892230987548828\n",
      "Markovain proj bw: Iter 8800, G Loss: 0.9391300082206726, D Loss: 1.1216495037078857\n",
      "Markovain proj bw: Iter 8900, G Loss: 0.6250239610671997, D Loss: 2.4791998863220215\n",
      "Markovain proj bw: Iter 9000, G Loss: 0.5666056871414185, D Loss: 1.5567293167114258\n",
      "Markovain proj bw: Iter 9100, G Loss: 0.3599089980125427, D Loss: 1.2212495803833008\n",
      "Markovain proj bw: Iter 9200, G Loss: 1.4969432353973389, D Loss: 1.2689826488494873\n",
      "Markovain proj bw: Iter 9300, G Loss: 1.3595352172851562, D Loss: 1.3437950611114502\n",
      "Markovain proj bw: Iter 9400, G Loss: 2.2924304008483887, D Loss: 0.8175251483917236\n",
      "Markovain proj bw: Iter 9500, G Loss: 1.7638856172561646, D Loss: 1.0079548358917236\n",
      "Markovain proj bw: Iter 9600, G Loss: 1.2404506206512451, D Loss: 1.1022592782974243\n",
      "Markovain proj bw: Iter 9700, G Loss: 1.3487801551818848, D Loss: 1.139904260635376\n",
      "Markovain proj bw: Iter 9800, G Loss: 0.7044943571090698, D Loss: 1.1118779182434082\n",
      "Markovain proj bw: Iter 9900, G Loss: 1.0022295713424683, D Loss: 1.5394495725631714\n",
      "Saving content.\n"
     ]
    }
   ],
   "source": [
    "prior = True\n",
    "condsampler_bw = CondLoaderSampler(prior_data_loader, args.plan, reverse=True)\n",
    "\n",
    "# if mini_batch_OT:\n",
    "#     condsampler_bw = OTSampler(condsampler_bw)\n",
    "\n",
    "markovian_projection(markovian_proj_iters, condsampler_bw, netG_bw, netD_bw,\n",
    "                         optimizerG_bw, optimizerD_bw,\n",
    "                         schedulerG_bw, schedulerD_bw, ema_g_bw, D_opt_steps=D_opt_steps, fw_or_bw='bw')\n",
    "\n",
    "x, y = condsampler_bw.sample(args.batch_size)\n",
    "\n",
    "x, x_t_1 = x.to(device), y.to(device)\n",
    "\n",
    "fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_bw,\n",
    "                                            args.num_timesteps, x_t_1, T,\n",
    "                                            args, return_trajectory=True)\n",
    "\n",
    "log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix='bw_after_M')\n",
    "\n",
    "transport_cost_model = calculate_transport_cost(x_t_1, fake_sample)\n",
    "transport_cost_ind = calculate_transport_cost(x_t_1, x)\n",
    "\n",
    "# FID\n",
    "sample_fn_bw = lambda y: sample_from_model(pos_coeff, netG_bw,\n",
    "                                            args.num_timesteps, y, T,\n",
    "                                            args, return_trajectory=True)[0]\n",
    "\n",
    "fid, ot_cost = compute_fid_and_ot_cost(true_dataloader_bw, model_input_dataloader_bw, sample_fn_bw)\n",
    "\n",
    "with ema_g_bw.average_parameters():\n",
    "\n",
    "    sample_fn_bw = lambda y: sample_from_model(pos_coeff, netG_bw,\n",
    "                                                args.num_timesteps, y, T,\n",
    "                                                args, return_trajectory=True)[0]\n",
    "\n",
    "    fid_ema, ot_cost_ema = compute_fid_and_ot_cost(true_dataloader_bw, model_input_dataloader_bw, sample_fn_bw)\n",
    "\n",
    "if wandb.run:\n",
    "    wandb.log({'T_cost_bw': transport_cost_model, 'T_cost_ind': transport_cost_ind,\n",
    "               'fid_bw': fid, 'fid_bw_ema': fid_ema,\n",
    "               'ot_cost_bw': ot_cost, 'ot_cost_bw_ema': ot_cost_ema})\n",
    "\n",
    "\n",
    "torch.save(netG_bw.state_dict(), os.path.join(exp_path, save_dir, f'netG_bw_0.pth'))\n",
    "\n",
    "with ema_g_bw.average_parameters():\n",
    "    torch.save(netG_bw.state_dict(), os.path.join(exp_path, save_dir, f'netG_bw_0_ema.pth'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a64d4",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = False\n",
    "for i in range(1, ipmf_iters + 1):\n",
    "    \n",
    "    # ----Forward model learning (y -> x)----\n",
    "    \n",
    "    if ema_start_ipmf:\n",
    "        with ema_g_fw.average_parameters():\n",
    "            \n",
    "            netG_fw_clone = NCSNpp(args).to(device)\n",
    "            \n",
    "            netG_fw_clone.load_state_dict(copy.deepcopy(netG_fw.state_dict()))\n",
    "\n",
    "            netG_fw = netG_fw_clone\n",
    "\n",
    "            ema_g_fw = ExponentialMovingAverage(netG_fw.parameters(), decay=args.ema_decay)\n",
    "            \n",
    "            optimizerG_fw = optim.Adam(netG_fw.parameters(),\n",
    "                                       lr=args.lr_g, betas = (args.beta1, args.beta2))\n",
    "    \n",
    "    bmgan_sample_bw = lambda x: sample_from_model(pos_coeff, netG_bw,\n",
    "                                                  args.num_timesteps, x.to(device),\n",
    "                                                  T, args, return_trajectory=True)[0]\n",
    "    \n",
    "    sampler_x = XSampler(CondLoaderSampler(data_loader))\n",
    "    \n",
    "    condsampler_fw = ModelCondSampler(sampler_x, bmgan_sample_bw, ema_g_bw)\n",
    "\n",
    "    markovian_projection(inner_ipmf_mark_proj_iters, condsampler_fw, netG_fw, netD_fw,\n",
    "                             optimizerG_fw, optimizerD_fw,\n",
    "                             schedulerG_fw, schedulerD_fw, ema_g_fw, D_opt_steps=D_opt_steps, fw_or_bw='fw')\n",
    "\n",
    "    x, y = condsampler_fw.sample(args.batch_size)\n",
    "\n",
    "    x, x_t_1 = x.to(device), y.to(device)\n",
    "\n",
    "    fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_fw,\n",
    "                                                args.num_timesteps, x_t_1, T,\n",
    "                                                args, return_trajectory=True)\n",
    "    \n",
    "    log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix='fw_after_M')\n",
    "\n",
    "    transport_cost_model = calculate_transport_cost(x_t_1, fake_sample)\n",
    "    transport_cost_ind = calculate_transport_cost(x_t_1, x)\n",
    "    \n",
    "    # FID\n",
    "    sample_fn_fw = lambda y: sample_from_model(pos_coeff, netG_fw,\n",
    "                                                args.num_timesteps, y, T,\n",
    "                                                args, return_trajectory=True)[0]\n",
    "    \n",
    "    fid, ot_cost = compute_fid_and_ot_cost(true_dataloader_fw, model_input_dataloader_fw, sample_fn_fw)\n",
    "    \n",
    "    with ema_g_fw.average_parameters():\n",
    "        \n",
    "        sample_fn_fw = lambda y: sample_from_model(pos_coeff, netG_fw,\n",
    "                                                    args.num_timesteps, y, T,\n",
    "                                                    args, return_trajectory=True)[0]\n",
    "        \n",
    "        fid_ema, ot_cost_ema = compute_fid_and_ot_cost(true_dataloader_fw, model_input_dataloader_fw, sample_fn_fw)\n",
    "    \n",
    "    if wandb.run:\n",
    "        wandb.log({'T_cost_fw': transport_cost_model, 'T_cost_ind': transport_cost_ind,\n",
    "                   'fid_fw': fid, 'fid_fw_ema': fid_ema,\n",
    "                   'ot_cost_fw': ot_cost, 'ot_cost_fw_ema': ot_cost_ema})\n",
    "        \n",
    "    torch.save(netG_fw.state_dict(), os.path.join(exp_path, save_dir, f'netG_fw_{i}.pth'))\n",
    "    \n",
    "    with ema_g_fw.average_parameters():\n",
    "        torch.save(netG_fw.state_dict(), os.path.join(exp_path, save_dir, f'netG_fw_{i}_ema.pth'))\n",
    "    \n",
    "    # ----Backward model learning (x -> y)----\n",
    "    \n",
    "    if ema_start_ipmf:\n",
    "        with ema_g_bw.average_parameters():\n",
    "            \n",
    "            netG_bw_clone = NCSNpp(args).to(device)\n",
    "            \n",
    "            netG_bw_clone.load_state_dict(copy.deepcopy(netG_bw.state_dict()))\n",
    "\n",
    "            netG_bw = netG_bw_clone\n",
    "            \n",
    "            ema_g_bw = ExponentialMovingAverage(netG_bw.parameters(), decay=args.ema_decay)\n",
    "            \n",
    "            optimizerG_bw = optim.Adam(netG_bw.parameters(),\n",
    "                                       lr=args.lr_g, betas = (args.beta1, args.beta2))\n",
    "    \n",
    "    bmgan_sample_fw = lambda x: sample_from_model(pos_coeff, netG_fw,\n",
    "                                                  args.num_timesteps, x.to(device),\n",
    "                                                  T, args, return_trajectory=True)[0]\n",
    "    \n",
    "    sampler_x = XSampler(CondLoaderSampler(data_loader, reverse=True))\n",
    "    \n",
    "    condsampler_bw = ModelCondSampler(sampler_x, bmgan_sample_fw, ema_g_fw)\n",
    "    \n",
    "    markovian_projection(inner_ipmf_mark_proj_iters, condsampler_bw, netG_bw, netD_bw,\n",
    "                             optimizerG_bw, optimizerD_bw,\n",
    "                             schedulerG_bw, schedulerD_bw, ema_g_bw, D_opt_steps=D_opt_steps, fw_or_bw='bw')\n",
    "    \n",
    "    x, y = condsampler_bw.sample(args.batch_size)\n",
    "    \n",
    "    x, x_t_1 = x.to(device), y.to(device)\n",
    "    \n",
    "    fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_bw,\n",
    "                                                args.num_timesteps, x_t_1, T,\n",
    "                                                args, return_trajectory=True)\n",
    "       \n",
    "    log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix='bw_after_M')\n",
    "    \n",
    "    transport_cost_model = calculate_transport_cost(x_t_1, fake_sample)\n",
    "    transport_cost_ind = calculate_transport_cost(x_t_1, x)\n",
    "    \n",
    "    # FID\n",
    "    \n",
    "    sample_fn_bw = lambda y: sample_from_model(pos_coeff, netG_bw,\n",
    "                                                args.num_timesteps, y, T,\n",
    "                                                args, return_trajectory=True)[0]\n",
    "    \n",
    "    fid, ot_cost = compute_fid_and_ot_cost(true_dataloader_bw, model_input_dataloader_bw, sample_fn_bw)\n",
    "    \n",
    "    with ema_g_bw.average_parameters():\n",
    "    \n",
    "        sample_fn_bw = lambda y: sample_from_model(pos_coeff, netG_bw,\n",
    "                                                    args.num_timesteps, y, T,\n",
    "                                                    args, return_trajectory=True)[0]\n",
    "    \n",
    "        fid_ema, ot_cost_ema = compute_fid_and_ot_cost(true_dataloader_bw, model_input_dataloader_bw, sample_fn_bw)\n",
    "\n",
    "    if wandb.run:\n",
    "        wandb.log({'T_cost_bw': transport_cost_model, 'T_cost_ind': transport_cost_ind,\n",
    "                   'fid_bw': fid, 'fid_bw_ema': fid_ema,\n",
    "                   'ot_cost_bw': ot_cost, 'ot_cost_bw_ema': ot_cost_ema})\n",
    "        \n",
    "    \n",
    "    torch.save(netG_bw.state_dict(), os.path.join(exp_path, save_dir, f'netG_bw_{i}.pth'))\n",
    "    \n",
    "    with ema_g_bw.average_parameters():\n",
    "        torch.save(netG_bw.state_dict(), os.path.join(exp_path, save_dir, f'netG_bw_{i}_ema.pth'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "274303e6-291f-4f43-828e-f90aad788eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = condsampler_bw.sample(args.batch_size)\n",
    "\n",
    "x, x_t_1 = x.to(device), y.to(device)\n",
    "\n",
    "fake_sample, x_0_pred_list, trajectory = sample_from_model(pos_coeff, netG_bw,\n",
    "                                            args.num_timesteps, x_t_1, T,\n",
    "                                            args, return_trajectory=True)\n",
    "   \n",
    "log_images(x, x_t_1, fake_sample, x_0_pred_list, trajectory, postfix='bw_after_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a174741-62b3-47e1-a14e-9ebb35c0cf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
